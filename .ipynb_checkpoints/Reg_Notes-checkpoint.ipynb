{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Models explain and predict (through quantifying relationships)\n",
    "- Models are approximations (i.e., they are not perfect representations)\n",
    "\n",
    "### Predictions Don't Have To Be Accurate to be Useful\n",
    "In general our models are not so precise if the relationship between our quantities are not perfect, but we can still make a reasonable guess using our models.\n",
    "\n",
    "* They have to generalize well to be useful\n",
    "* Real life data comes installed with lots of unexpected variation\n",
    "* Nothing in life is 100% certain, not even relationships ðŸ™„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear regression is a method to determine the coefficients of linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Simple linear regression is an approach for predicting a **continuous response** using a **single feature**. It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are called the **model coefficients**:\n",
    "\n",
    "- We must \"learn\" the values of these coefficients to create our model.\n",
    "- And once we've learned these coefficients, we can use the model to predict **something**.\n",
    "\n",
    "#### Estimating (\"learning\") model coefficients\n",
    "- Coefficients are estimated during the model fitting process using the least squares criterion.\n",
    "- We find the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\").\n",
    "\n",
    "_Residuals: The difference between the observed value of the dependent variable (y) and the predicted value (Å·) is called the residual (e). Each data point has one residual._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to **minimize the predictive error of our models**. (I.e. we need an objective function.) How do we quantify the error in our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sum of Squared Errors (SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "$$ SSE = \\sum_{i=1}^{n}(y_i - f(x_i))^2 = \\sum_{i=1}^{n}(y_i - \\hat y)^2 $$\n",
    "\n",
    "$x_i$ -- a given x value\n",
    "\n",
    "$y_i$ -- actual y value\n",
    "\n",
    "$f(x_i)$-- the model's predicted y value\n",
    "\n",
    "$\\hat y $ -- predicted y value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### SSE can be decomposed<sup>1</sup> into error due to Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$SSE \\sim E(y_i - \\hat{f}(x_i))^2 = Var(\\hat{f}(x_i))\\ + [Bias(\\hat{f}(x_i))]^2 + Var(\\epsilon)$$\n",
    "<sup>1</sup>See the derivation of this result [here](https://theclevermachine.wordpress.com/tag/bias-variance-decomposition/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Bias**\n",
    "* Your model makes assumptions about the shape of the data and consistently gets it wrong as it is run on new sample data.\n",
    "\n",
    "**Variance**\n",
    "* Imagine building your model many times, on different slices of data. Variance is related to how much your predictions for a given $x_i$ differ each time you make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### The tradeoff:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-22T22:23:18.051174",
     "start_time": "2016-10-22T22:23:17.826013"
    },
    "hidden": true
   },
   "source": [
    "![](https://camo.githubusercontent.com/be96d619bff8883343cf541ed1405a8f7f5991cc/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f6d6174682f632f622f632f63626336353331306430396136656661363330643863316633336364666138382e706e67)\n",
    "![](https://camo.githubusercontent.com/34d8f46b4220c71b359f55db15ed9124474b397d/687474703a2f2f73636f74742e666f72746d616e6e2d726f652e636f6d2f646f63732f646f63732f4269617356617269616e63652f6269617376617269616e63652e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Example variance and bias code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-22T22:19:50.741038",
     "start_time": "2016-10-22T22:19:50.686726"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from w3d2-bias-variance-lecture\n",
    "domain = np.array([x[0] for x in data]) # The x values we're \"observing\"\n",
    "Y = np.array([x[1] for x in data]) # The values we are trying to predict\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    X = monomials(domain, i) \n",
    "    # Create linear regression object and fit it to X and Y\n",
    "    regr = regr.fit(X, Y)\n",
    "\n",
    "    yhat = regr.predict(X)\n",
    "    sse = np.mean((np.mean(yhat) - Y) ** 2)\n",
    "    var = np.var(yhat)\n",
    "    bias = sse - var - 0.01\n",
    "    \n",
    "    # The coefficients\n",
    "    print('Coefficients: %.4f' % regr.coef_)\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % regr.score(X, Y))\n",
    "\n",
    "    # The mean square error\n",
    "    print(\"Residual sum of squares: %.2f\" % sse)\n",
    "\n",
    "    print(\"Bias: {bias}\".format(bias=bias))\n",
    "    print(\"Variance: {var}\".format(var=var))\n",
    "        \n",
    "    # Plot outputs\n",
    "    plt.scatter(domain, Y,  color='black')\n",
    "    plt.plot(domain, regr.predict(X), color='blue', linewidth=3)\n",
    "\n",
    "    plt.title(\"n = \" + str(i))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization (theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regularization helps avoid overfitting by limiting model complexity\n",
    "* Mathematically this works by penalizing models with greater complexity\n",
    "* Regularized models will often fit alternate datasets better than a model that's been overfit on the training data\n",
    "  * [But what if minimizing the error gives us a model that is great on our training data, but not so great on out-of-sample data?\n",
    "  * When might this happen? When could we have **too complex a model**?\n",
    "  * Few samples compared to the number of features (predictors)\n",
    "  * So if we have a large number of features, we can end up with a model that fits our training set well, but fails to generalize to our test data]\n",
    "* To remedy this, we can make a **tradeoff**: We can increase the bias of our model in order to reduce the variance. * * It can make sense to do this when the increase in bias is small compared to the decrease in variance.\n",
    "* We have two choices:\n",
    "  * Remove selected features manually - problem is this may remove some valuable info\n",
    "  * **Regularization** - keep all features, but reduce their \"pull\" in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model Complexity to Prediction Error Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "<img src=\"http://i.imgur.com/C9EmsUV.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This \"pull\" reduction is accomplished by constraining their coefficients, or by **regularization**\n",
    "* That is we impose a cost or a **penalty** to having a high $Beta$\n",
    "* This means that we have moved away from the minimum error (increased bias) in order to the reduce variance of our model\n",
    "#### Cost Function\n",
    "* Minimize\n",
    "* In linear model, cost function is sum of squares\n",
    "* Cost = Bias (sum of squares) - ????\n",
    "* Penalty = Variance (coefficients, regularization) - ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Cost Penalty Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"http://i.imgur.com/CkRe7Ru.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we minimized the sum of squared error, but now we are minimizing that plus the size of the coefficients times some weight (either called lambda or alpha). Theta here is the size of our all our coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-22T23:05:43.984092",
     "start_time": "2016-10-22T23:05:43.979956"
    }
   },
   "source": [
    "$$ min \\sum ( y_{i} - \\hat{y} )^2 + \\lambda \\theta $$\n",
    "$$ \\lambda $$ <center>may also be called</center> $$ \\alpha $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso (L1) and Ridge (L2) - most common penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 vs L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://i.imgur.com/c8BZW3i.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression Metrics Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
