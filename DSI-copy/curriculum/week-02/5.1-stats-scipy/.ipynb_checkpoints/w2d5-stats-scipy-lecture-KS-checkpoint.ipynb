{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Stats Review & Intro to SciPy\n",
    "Week 2 | Lesson 5.1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "\n",
    "- Explain Type I and Type II errors\n",
    "- Explain t-testing and demonstrate it with scipy\n",
    "- Contrast t-testing with simulation solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LESSON GUIDE\n",
    "| TIMING  | TYPE  | TOPIC  |\n",
    "|:-:|---|---|\n",
    "| 10 min  | [Demo](#introduction)   | Significance levels, Type I and Type II errors  |\n",
    "| 10 min  | [Demo](#demo)  | Law of large numbers and central limit theorem  |\n",
    "| 10 min  | [Demo / Guided Practice](#demo)  | T-testing revisited  |\n",
    "| 20 min  | [Independent Practice](#ind-practice)  | T-testing  |\n",
    "| 10 min  | [Demo /Guided Practice](#demo)  | Computational approaches  |\n",
    "| 30 min  | [Independent Practice](#ind-practice)  |  Computational statistics |\n",
    "| 5 min  | [Conclusion](#conclusion)  | |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Significance levels, Type I and Type II errors\n",
    "\n",
    "Type I errors occur when the researcher rejects a null hypothesis when it is actually true. The probability of committing a Type I error is called the significance level, often denoted $\\alpha$.\n",
    "\n",
    "A Type II error occurs when the researcher wrongly accepts a null hypothesis that is false.  The probability of committing a Type II error is often denoted by $\\beta$.\n",
    "\n",
    "$$\\alpha\\ =\\ P(Reject\\ H_0\\ |\\ H_0\\ is\\ true) = P(Type\\ I\\ error)$$\n",
    "\n",
    "\n",
    "$$\\beta\\ =\\ P(Not Reject\\ H_0\\ |\\ H_a\\ is\\ true) = P(Type\\ II\\ error)$$\n",
    "\n",
    "$$\\beta\\ =\\ P(Not Reject\\ H_0\\ |\\ H_0\\ is\\ false) = P(Type\\ II\\ error)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of large numbers\n",
    "\n",
    "If $Y_1,\\ Y_2\\ ...,\\ Y_n$ are independently and identically distributed (i.i.d) with mean $\\mu$ and finite variance, a sample mean converges in probability to $\\mu$.\n",
    "\n",
    "This means that for sufficiently large N, $\\bar{Y}\\ -\\ \\mu$ is ~ 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central limit theorem\n",
    "\n",
    "- If $Y_1,\\ Y_2\\ ...,\\ Y_n$ are i.i.d with mean $\\mu$ and variance $\\sigma^2$, then when *n* is large, sample mean $\\hat{\\mu}$ is approximately normally distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "- $\\hat{\\mu}$ is asymptotically normally distributed\n",
    "- So? Well, this allows us to assume that some random variables are normally distributed, and to make inferences about the likelihood of observations drawn from that distribution. For instance, it implies:\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}\\ \\sim \\ N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## T-tests revisited\n",
    "\n",
    "Does $\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}$ look familiar? If we use the sample standard deviation in the denominator, that's the t-statistic!\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{s/\\sqrt{n}}$$\n",
    "\n",
    "And if n is large, then the value of the t-statistic is approximately normally distributed. (If n is small and the sample observations are normally distributed, then it has a t-distribution.)\n",
    "\n",
    "$\\frac{s}{\\sqrt{n}}$ is also called the standard error, $s.e.of  \\hat\\mu $\n",
    "\n",
    "* Numerator: signal\n",
    "* Denominator: noise\n",
    "* Way of standardizing mean (by putting mean at 0)\n",
    "    * Assume a probability distribution of N(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P-values and hypothesis testing, revisited\n",
    "\n",
    "If we can assume a probability distribution, e.g. N(0,1), then we can calculate the likelihood of seeing some value given that assumption.\n",
    "\n",
    "![](./norm_dist_probs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis testing with t-tests, review\n",
    "\n",
    "Let's say 1165 bootcamp applicants take a GA admissions test in 2017, with an average score of 60.86 and a standard deviation of 8.02. The expected score for all bootcamp applicants (not just GA) is 59. Do GA applicants have the same expected score?\n",
    "\n",
    "We can estimate $\\mu$, the GA applicant population mean, with our sample mean. $\\hat{\\mu} = \\bar{Y} = 60.86$. The sample standard deviation *s* is 8.02.\n",
    "\n",
    "Standard error of the estimate is then $se(\\hat{\\mu}) = \\frac{s}{\\sqrt{n}} = \\frac{8.02}{\\sqrt{1165}} = 0.235$\n",
    "\n",
    "> What are our null and alternative hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothesis is that there is no difference\n",
    "* Alternative hypothesis is that there is a difference (not 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$H_0: \\hat\\mu = 59$$\n",
    "$$H_a: \\hat\\mu \\neq 59$$\n",
    "\n",
    "Under $H_0,\\ t = \\frac{\\hat{\\mu} - 59}{se(\\hat{\\mu})}$ is approximate normally distributed with N(0,1). If t falls far on the tail, the p-value is low and we'll reject $H_0$.\n",
    "\n",
    "Calculate the t-statistic and [look up its p-value](https://graphpad.com/quickcalcs/PValue1.cfm]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$t = \\frac{60.86 - 59}{0.2350} = 7.915$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "P < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Again, but now with scipy ('skippy'?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 53.26524642  58.64445885  59.26615073 ...,  57.78177772  55.42126582\n",
      "  65.92945246]\n",
      "8.05037070851 61.1582143415\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.random.seed(7654567)  # fix seed to get the same result - subject of our lab\n",
    "rvs = stats.norm.rvs(loc=60.86, scale=8.02, size=(1165))\n",
    "print rvs\n",
    "#loc = mean; scale = sd\n",
    "\n",
    "# Note that the mean and std of our generated data aren't precisely the same.\n",
    "print np.std(rvs), np.mean(rvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=9.1465051826423593, pvalue=2.5558469858139369e-19)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(rvs, 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which scipy function to use?\n",
    "\n",
    "A few common t-tests include:\n",
    "- One-sample t-test. Used to determine whether a hypothesized population\n",
    "    mean differs significantly from an observed sample mean.\n",
    "- Two-sample t-test. Used to determine whether the difference between samples means differs significantly from the              hypothesized difference between population means.\n",
    "- Paired t-test. Used to test the significance of the difference\n",
    "    between paired means.\n",
    "\n",
    "Scipy has methods for all of these, and more. Which one do we want?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the documentation, we want `scipy.stats.ttest_1samp`, for our one-sample t-test.\n",
    "\n",
    "To verify, compare our formula with the scipy code, [here](https://github.com/scipy/scipy/blob/v0.14.0/scipy/stats/stats.py#L3037)\n",
    "\n",
    "\n",
    "```python\n",
    " a, axis = _chk_asarray(a, axis)\n",
    "    n = a.shape[axis]\n",
    "    df = n - 1\n",
    "\n",
    "    d = np.mean(a, axis) - popmean\n",
    "    v = np.var(a, axis, ddof=1)\n",
    "    denom = np.sqrt(v / float(n))\n",
    "\n",
    "    t = np.divide(d, denom)\n",
    "    t, prob = _ttest_finish(df, t)\n",
    "\n",
    "    return t, prob\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Look good? Okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=9.1465051826423593, pvalue=2.5558469858139369e-19)\n",
      "Ttest_1sampResult(statistic=-9.0338332344805128e-12, pvalue=0.99999999999279354)\n"
     ]
    }
   ],
   "source": [
    "# Test if mean of random sample is equal to true mean, and different mean.\n",
    "# We reject the null hypothesis in the second case and don’t reject it in the first case.\n",
    "\n",
    "print stats.ttest_1samp(rvs,59.0) #reject null hypothesis, p that given hypothesized population mean (59), what\n",
    "#is probability of seeing rvs\n",
    "print stats.ttest_1samp(rvs,61.1582143415) #not reject null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: classic t-tests (20 minutes)\n",
    "\n",
    "In pairs or trios, look at the SAT test data from Project 1. (We'll assume it's a sample of results, rather than the population results.) Together, form null and alternative hypotheses about some of the scores. \n",
    "(E.g., H0: the mean difference between states' verbal and math scores is 0; or H0: the population math score is 550.)\n",
    "\n",
    "Choose a significance level and conduct an appropriate t-test.\n",
    "\n",
    "- [t-tests](http://iaingallagher.tumblr.com/post/50980987285/t-tests-in-python)\n",
    "- [t distribution](http://stattrek.com/probability-distributions/t-distribution.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Verbal</th>\n",
       "      <th>Math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT</td>\n",
       "      <td>82</td>\n",
       "      <td>509</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJ</td>\n",
       "      <td>81</td>\n",
       "      <td>499</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA</td>\n",
       "      <td>79</td>\n",
       "      <td>511</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>77</td>\n",
       "      <td>495</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NH</td>\n",
       "      <td>72</td>\n",
       "      <td>520</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Rate  Verbal  Math\n",
       "0    CT    82     509   510\n",
       "1    NJ    81     499   513\n",
       "2    MA    79     511   515\n",
       "3    NY    77     495   505\n",
       "4    NH    72     520   516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sat = pd.read_csv('/Users/kristensu/Dropbox/GA-DSI/DSI-copy/projects/projects-weekly/project-01/assets/sat_scores.csv')\n",
    "sat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532.019230769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-58.142487084417603, pvalue=2.7364912639127121e-48)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbal_mean = np.mean(sat['Verbal'])\n",
    "print verbal_mean\n",
    "stats.ttest_1samp(sat['Verbal'], 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-3.7041646377908148, pvalue=0.00052211980150622395)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_mean = np.mean(sat['Math'])\n",
    "print math_mean\n",
    "stats.ttest_1samp(sat['Math'],550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-0.10396304076958617, pvalue=0.91760644500200694)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(sat['Math'],np.mean(sat['Verbal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.076401246238828047, pvalue=0.93924953595020755)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just testint out; stats.ttest_ind assumes identical variances (works in this instance)\n",
    "stats.ttest_ind(sat['Math'],sat['Verbal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"t-testing\"></a>\n",
    "## Demo/Guided Practice: computational approaches (10 minutes)\n",
    "\n",
    "Now that computational power is cheap and available (and you know Python!), we have an alternative way of approaching these questions: iteratively calculate the probability of observing some result.\n",
    "\n",
    "For example:\n",
    "\n",
    "```Python\n",
    "# Simulating a binomial variable (e.g. seeing heads in 20 out of 30 coin flips )\n",
    "m = 0\n",
    "for i in range(10000):\n",
    "    trials = np.random.randint(2, size = 30)\n",
    "    if (trials.sum() >= 20):\n",
    "        m += 1\n",
    "p = m / 10000.0\n",
    "p\n",
    "```\n",
    "\n",
    "> Check: what is this doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This was an example if **simulating** your experiment -- you can do this if you have an a priori model of what happens.\n",
    "\n",
    "If you don't have an a priori model, another option is **shuffling** results:\n",
    "\n",
    "(Example from: http://cs.nyu.edu/shasha/papers/StatisticsIsEasyExcerpt.html)\n",
    "\n",
    "\"Imagine we have given some people a placebo and others a drug. The measured improvement (the more positive the better) is\n",
    "\n",
    "Placebo: 54 51 58 44 55 52 42 47 58 46\n",
    "\n",
    "Drug: 54 73 53 70 73 68 52 65 65\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"As you can see, the drug seems more effective on the average (the average measured improvement is 63.7 for the drug and 50.7 for the placebo). But is this difference in the average real? Formula-based statistics would use a t-test which entails certain assumptions about normality and variance, but we are going to look just at the samples themselves and shuffle the labels.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What this means can be illustrated as follows. We put all the people in a table having two columns value and label (P for placebo and D for drug).\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P |\n",
    "|51\t| P |\n",
    "|58\t| P |\n",
    "|44\t| P |\n",
    "|55\t| P |\n",
    "|52\t| P |\n",
    "|42\t| P |\n",
    "|47\t| P |\n",
    "|58\t| P |\n",
    "|46\t| P |\n",
    "|54\t| D |\n",
    "|73\t| D |\n",
    "|53\t| D |\n",
    "|70\t| D |\n",
    "|73\t| D |\n",
    "|68\t| D |\n",
    "|52\t| D |\n",
    "|65\t| D |\n",
    "|65\t| D |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Shuffling the labels means that we will take the Ps and Ds and randomly distribute them among the patients. (Technically, we do a uniform random permutation of the label column.)\n",
    "\n",
    "This might give:\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P \n",
    "|51\t| P\n",
    "|58\t| D\n",
    "|44\t| P\n",
    "|55\t| P\n",
    "|52\t| D\n",
    "|42\t| D\n",
    "|47\t| D\n",
    "|58\t| D\n",
    "|46\t| D\n",
    "|54\t| P\n",
    "|73\t| P\n",
    "|53\t| P\n",
    "|70\t| D\n",
    "|73\t| P\n",
    "|68\t| P\n",
    "|52\t| D\n",
    "|65\t| P\n",
    "|65\t| D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then look at the difference in the average P value vs. the average D value here. We get an average of 59.0 for P and 54.4 for D. We repeat this shuffle-then-measure procedure 10,000 times and ask what fraction of time we get a difference between drug and placebo greater than or equal to the measured difference of 63.7 - 50.7 = 13. The answer in this case is under 0.001.\"\"\n",
    "\n",
    "> Check: what are the benefits of a computational strategy? The risks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: finding probabilities computationally (30 minutes)\n",
    "\n",
    "In pairs or trios, design and code a computational way of finding the probability of rolling a 6 at least one-third of the time on a fair die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusion (5 mins)\n",
    "\n",
    "- We make trade-offs between risking Type I and Type II errors\n",
    "- There are varieties of t-tests, and scipy methods for conducting them\n",
    "- Simulations / computation strategies are an alternative to parametric statistical inference"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
