{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 4: Web Scraping & Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect data on data science salary trends from a job listings aggregator for your analysis.\n",
    "  - Select and parse data from at least ~1000 postings for jobs, potentially from multiple location searches.\n",
    "2. Find out what factors most directly impact salaries (title, location, department, etc.). In this case, we do not want to predict mean salary as would be done in a regression. Your boss believes that salary is better represented in categories than continuously\n",
    "  - Test, validate, and describe your models. What factors predict salary category? How do your models perform?\n",
    "3. Prepare a presentation for your Principal detailing your analysis.\n",
    "\n",
    "**BONUS PROBLEMS:**\n",
    "1. Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your logistic regression models to ease her mind, and explain what it is doing and any tradeoffs. Plot the ROC curve.\n",
    "2. Text variables and regularization:\n",
    "  - **Part 1**: Job descriptions contain more potentially useful information you could leverage. Use the job summary to find words you think would be important and add them as predictors to a model.\n",
    "  - **Part 2**: Gridsearch parameters for Ridge and Lasso for this model and report the best model.\n",
    "\n",
    "\n",
    "**Goal:** Scrape & clean data, run logistic regression, derive insights, present findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium import webdriver\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "from collections import Counter # Keep track of our term counts\n",
    "from nltk.corpus import stopwords # Filter out stopwords, such as 'the', 'or', 'and'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Data - Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "############### EDIT THESE CONSTANTS\n",
    "############### \n",
    "###############        EDIT THESE CONSTANTS\n",
    "\n",
    "MAX_RESULTS_PER_CITY = 1000      ### DO NOT SET MORE THAN 1000\n",
    "URL_SEARCH_TERM = 'Data Scientist' ### DO NOT SET MORE THAN SINGLE SEARCH TERM (TITLE)\n",
    "CITY_SET = ['New York', 'Chicago', 'San Francisco', 'Austin', 'Atlanta', '', 'Boston', 'Seattle'\\\n",
    "            'Los Angeles','Washington, DC', 'San Jose','Denver', 'Atlanta','Houston',\\\n",
    "            'Dallas','Nashville','San Diego','Cleveland','Minneapolis','Baltimore','Philadelphia','Detroit']\n",
    "###############\n",
    "################################################################\n",
    "\n",
    "\n",
    "def extract_location_from_resultRow(result):\n",
    "    try:\n",
    "        location = (result.find(class_='location').text.strip())\n",
    "    except:\n",
    "        location = ''\n",
    "    return location\n",
    "\n",
    "def extract_company_from_resultRow(result):\n",
    "    try:\n",
    "        company = (result.find(class_='company').text.strip())\n",
    "    except:\n",
    "        company = ''\n",
    "    return company\n",
    "\n",
    "def extract_jkid_from_resultRow(result):\n",
    "    try:\n",
    "        row = (result.find(class_='jobtitle turnstileLink'))\n",
    "        jkid = result['data-jk']\n",
    "    except: \n",
    "        jkid = ''\n",
    "    return jkid\n",
    "\n",
    "def extract_title_from_resultRow(result):\n",
    "    try:\n",
    "        title = (result.find(class_='turnstileLink'))\n",
    "        title_text = title.text\n",
    "    except: \n",
    "        title_text = ''\n",
    "    return title_text\n",
    "\n",
    "def extract_salary_from_resultRow(result):\n",
    "    try:\n",
    "        salary = (result.find(class_='snip').find('nobr').text)\n",
    "    except:\n",
    "        salary = ''\n",
    "    salary_text = salary\n",
    "    return salary_text\n",
    "\n",
    "def extract_reviews_from_resultRow(result):\n",
    "    try:\n",
    "        reviews = (result.find(class_='slNoUnderline').text.strip().strip(' reviews').replace(',',''))\n",
    "    except: \n",
    "        reviews = ''\n",
    "    return reviews\n",
    "\n",
    "def extract_stars_from_resultRow(result):\n",
    "    try: \n",
    "        stars = (result.find(class_='rating')['style']).split(';background-position:')[1].split(':')[1].split('px')[0].strip()\n",
    "    except: \n",
    "        stars = ''\n",
    "    return stars\n",
    "\n",
    "def extract_date_from_resultRow(result):\n",
    "    try: \n",
    "        date = (result.find(class_='date').text.strip(' ago').strip())\n",
    "    except: \n",
    "        date = ''\n",
    "    return date\n",
    "\n",
    "def extract_summary_from_resultRow(result):\n",
    "    try: \n",
    "        summary = (result.find(\"span\", {\"itemprop\" : \"description\"}).text.strip())\n",
    "    except: \n",
    "        summary = ''\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T00:33:31.710943",
     "start_time": "2016-10-17T00:05:15.512276"
    },
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "dcap[\"phantomjs.page.settings.userAgent\"] = (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.PhantomJS(executable_path='/Users/kristensu/Downloads/phantomjs-2.1.1-macosx/bin/phantomJS', desired_capabilities=dcap)\n",
    "driver.set_window_size(1024, 768) \n",
    "\n",
    "for city in CITY_SET:\n",
    "    job_dict = []\n",
    "    now = datetime.datetime.now()\n",
    "    for start in range(0, MAX_RESULTS_PER_CITY, 10):\n",
    "\n",
    "        URL = \"http://www.indeed.com/jobs?q=\"+urllib.quote(URL_SEARCH_TERM)+\"&l=\"+urllib.quote(city)+\"&start=\"+str(start)\n",
    "        driver.get(URL)\n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "\n",
    "        for i in soup.findAll(\"div\", {\"data-tn-component\" : \"organicJob\"}):\n",
    "\n",
    "            location = extract_location_from_resultRow(i)\n",
    "            company = extract_company_from_resultRow(i)\n",
    "            summary = extract_summary_from_resultRow(i)\n",
    "            jkid = extract_jkid_from_resultRow(i)\n",
    "            title = extract_title_from_resultRow(i)\n",
    "            salary = extract_salary_from_resultRow(i)\n",
    "            reviews = extract_reviews_from_resultRow(i)\n",
    "            stars = extract_stars_from_resultRow(i)\n",
    "            post_date = extract_date_from_resultRow(i)\n",
    "\n",
    "            job_dict.append([location, company, summary, jkid, title, salary, stars, reviews, post_date, now])\n",
    "            \n",
    "        job_df = pd.DataFrame(job_dict, columns=['location', 'company', 'summary', 'jkid', 'title', 'salary', 'stars', 'reviews', 'post_date', 'pull_date'])       \n",
    "\n",
    "    job_df.to_csv('scrape'+city+'_'+str(MAX_RESULTS_PER_CITY)+'.csv', encoding='utf-8')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Data - glassdoor.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Insert Amish's code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Merge df's here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import master.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:32.995644",
     "start_time": "2016-10-17T09:00:32.867074"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/core/ops.py:714: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    }
   ],
   "source": [
    "master_df = pd.read_csv('master-3.csv')\n",
    "\n",
    "# DELETE ANY HEADER ROWS LEFT OVER FROM CSV MERGE\n",
    "try: master_df = master_df[master_df['reviews'] != 'reviews'] \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:33.324025",
     "start_time": "2016-10-17T09:00:33.040902"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### REVIEWS CLEAN TO FLOAT\n",
    "######\n",
    "\n",
    "master_df['reviews'] = master_df['reviews'].fillna(0)\n",
    "\n",
    "def indeed_review_cleanup(review): \n",
    "    try:\n",
    "        review = review.str.replace(',','')\n",
    "        review = review.strip(' reviews')\n",
    "        review = review.strip(' review')\n",
    "        review = review.strip('reviews')\n",
    "        review = review.strip()\n",
    "        review = float(review)\n",
    "    except:\n",
    "        #print review\n",
    "        pass\n",
    "    return review\n",
    "\n",
    "master_df['clean_review'] = master_df[['reviews']].applymap(lambda x:indeed_review_cleanup(x))\n",
    "\n",
    "master_df['clean_review'].sort_values().unique()\n",
    "\n",
    "master_df['clean_review'] = master_df['clean_review'].astype(float)\n",
    "master_df['reviews'] = master_df['clean_review']\n",
    "master_df.drop('clean_review', axis=1, inplace=True)\n",
    "\n",
    "#########  END CLEAN REVIEWS\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:33.548237",
     "start_time": "2016-10-17T09:00:33.326850"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### POST_DATE CLEAN TO FLOAT\n",
    "######\n",
    "\n",
    "try:\n",
    "    master_df['clean_post_date'] = master_df['post_date']\n",
    "except: pass\n",
    "\n",
    "\n",
    "def post_date_to_day_float(dateValue):\n",
    "    try:\n",
    "        temp = dateValue\n",
    "        dateValue.replace('s','')\n",
    "        if 'day' in dateValue:\n",
    "            temp = dateValue.split()[0]\n",
    "        elif 'hour' in dateValue:\n",
    "            temp = dateValue.split()[0]\n",
    "            temp = float(temp)/24\n",
    "        elif 'minute' in dateValue:\n",
    "            temp = dateValue.split()[0]\n",
    "            temp = float(temp)/24/60\n",
    "        if '+' in dateValue:\n",
    "            temp = 45           \n",
    "    except: \n",
    "        pass\n",
    "    return temp\n",
    "\n",
    "master_df['clean_post_date'] = master_df[['clean_post_date']].applymap(lambda x: post_date_to_day_float(x))\n",
    "\n",
    "master_df['clean_post_date'].sort_values().unique()\n",
    "\n",
    "master_df['clean_post_date'] = master_df['clean_post_date'].astype(float)\n",
    "master_df['post_date'] = master_df['clean_post_date']\n",
    "master_df.drop('clean_post_date', axis=1, inplace=True)\n",
    "master_df.rename(columns = {'post_date':'post_date_daysAgo'}, inplace=True)\n",
    "\n",
    "#########  END CLEAN POST_DATE\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:33.630586",
     "start_time": "2016-10-17T09:00:33.551409"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### STARS CLEAN TO FLOAT\n",
    "######\n",
    "\n",
    "\n",
    "master_df['clean_stars'] = master_df['stars'].fillna(0)\n",
    "master_df['clean_stars'] = master_df[['stars']].astype(float).applymap(lambda x: x//6/2)\n",
    "\n",
    "\n",
    "master_df['stars'] = master_df['clean_stars']\n",
    "master_df.drop('clean_stars', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#########  END CLEAN STARS\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:33.678361",
     "start_time": "2016-10-17T09:00:33.638226"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####Create JOB_LINK column from JKID\n",
    "#####\n",
    "\n",
    "master_df['job_link'] = master_df[['jkid']].applymap(lambda x: 'http://www.indeed.com/rc/clk?jk='+x)\n",
    "\n",
    "#########  END JOB_LINK COLUMN\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:00:34.448718",
     "start_time": "2016-10-17T09:00:34.210685"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Location Cleanup\n",
    "#####\n",
    "\n",
    "def location_cleanup(location):\n",
    "    temp = location\n",
    "    temp_city = location.split(',')[0]\n",
    "    try:\n",
    "        temp_state = location.split(',')[1].split()[0]\n",
    "    except: \n",
    "        temp_state = ''\n",
    "    return temp_city+\", \"+temp_state\n",
    "    \n",
    "master_df['location_clean'] = master_df[['location']].applymap(lambda x: location_cleanup(x))\n",
    "master_df['location_clean'].sort_values().unique()\n",
    "\n",
    "master_df['location'] = master_df['location_clean']\n",
    "master_df.drop('location_clean', axis=1, inplace=True)\n",
    "\n",
    "#########  END LOCATION CLEANUP COLUMN\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T09:01:07.599900",
     "start_time": "2016-10-17T09:01:07.380588"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Salary Cleanup\n",
    "#####\n",
    "\n",
    "master_df['salary'] = master_df['salary'].fillna(0)\n",
    "\n",
    "def cleanup_salary(salary):\n",
    "    if \"year\" in str(salary):\n",
    "        temp = salary.strip(\" a year\")\n",
    "        temp = temp.split('-')\n",
    "        low_range = int(temp[0].strip().replace(\"$\",\"\").replace(\",\",\"\"))\n",
    "        high_range = int(temp[-1].strip().replace(\"$\",\"\").replace(\",\",\"\"))\n",
    "        avg = (low_range + high_range) / 2\n",
    "        salary_list = [low_range,high_range,avg]\n",
    "    elif \"month\" in str(salary):\n",
    "        temp = salary.replace(\"a month\",\"\")\n",
    "        temp = temp.split('-')\n",
    "        low_range = int(temp[0].replace(\"$\",\"\").replace(\",\",\"\"))*12\n",
    "        high_range = int(temp[-1].replace(\"$\",\"\").replace(\",\",\"\"))*12\n",
    "        avg = (low_range + high_range) / 2\n",
    "        salary_list = [low_range,high_range,avg]\n",
    "    elif \"hour\" in str(salary):\n",
    "        temp = salary.replace(\"an hour\",\"\")\n",
    "        temp = temp.split('-')\n",
    "        low_range = float(temp[0].replace(\"$\",\"\").replace(\",\",\"\"))*2080\n",
    "        high_range = float(temp[-1].replace(\"$\",\"\").replace(\",\",\"\"))*2080\n",
    "        avg = (low_range + high_range) / 2\n",
    "        salary_list = [low_range,high_range,avg]\n",
    "    else:\n",
    "        salary_list = [0,0,0]\n",
    "        low_range = 0\n",
    "        high_range = 0\n",
    "        avg = 0\n",
    "        \n",
    "    return low_range, high_range, avg\n",
    "master_df['salary_clean'] = master_df[['salary']].applymap(lambda x: cleanup_salary(x))\n",
    "\n",
    "master_df['salary'] = master_df['salary_clean']\n",
    "\n",
    "master_df['sal_low'] = master_df['salary'].apply(lambda x: x[0])\n",
    "master_df['sal_high'] = master_df['salary'].apply(lambda x: x[1])\n",
    "master_df['sal_avg'] = master_df['salary'].apply(lambda x: x[2])\n",
    "\n",
    "master_df.drop('salary_clean', axis=1, inplace=True)\n",
    "master_df.drop('salary', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#########  END SALARY CLEANUP COLUMN\n",
    "###################\n",
    "#Add Comment\n",
    "# master_df['salary_clean'] = master_df[['salary']].applymap(lambda x: cleanup_salary(x))\n",
    "\n",
    "# master_df['salary'] = master_df['salary_clean']\n",
    "# master_df.drop('salary_clean', axis=1, inplace=True)\n",
    "\n",
    "#########  END SALARY CLEANUP COLUMN\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-17T08:54:44.800034",
     "start_time": "2016-10-17T08:54:44.471688"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# has_salary = master_df[master_df['salary'] != (0,0,0)].shape[0]\n",
    "# all_records = master_df.shape[0]\n",
    "# print \"Job listings with salary info:\", has_salary\n",
    "# print \"Total job listings: \", all_records\n",
    "# print \"Salaried listings / Total listings\", round((float(has_salary) / all_records) * 100, 3), '%'\n",
    "# master_df.head(5)\n",
    "# master_df['title'].sort_values().unique()\n",
    "\n",
    "# stacked = pd.DataFrame(master_df['summary'].str.split().tolist()).stack()\n",
    "# final = pd.DataFrame(stacked.value_counts())\n",
    "# final.reset_index(inplace=True)\n",
    "# final['unique'] = final['index'].sort_values().unique()\n",
    "# final['unique']\n",
    "# import nltk\n",
    "# final['tagged'] = final[['index']].applymap(lambda x: nltk.pos_tag(x.strip()))\n",
    "# final.info()\n",
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URL = 'https://www.expatistan.com/cost-of-living/index/north-america' \n",
    "driver = webdriver.PhantomJS(executable_path='/Users/kristensu/Downloads/phantomjs-2.1.1-macosx/bin/phantomjs')\n",
    "driver.set_window_size(1024, 768) \n",
    "driver.get(URL)\n",
    "soup = BeautifulSoup(driver.page_source,'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = []\n",
    "r = []\n",
    "for city in soup.findAll('table',class_=\"city-index\"):\n",
    "    for cities in soup.findAll('td',class_='city-name'):\n",
    "        c.append(cities.text)\n",
    "    for rank in soup.findAll('td',class_='price-index'):\n",
    "        r.append(rank.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13138, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "      <th>jkid</th>\n",
       "      <th>title</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>post_date_daysAgo</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>search_city</th>\n",
       "      <th>job_link</th>\n",
       "      <th>sal_low</th>\n",
       "      <th>sal_high</th>\n",
       "      <th>sal_avg</th>\n",
       "      <th>COL_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Machine learning, data visualization, statisti...</td>\n",
       "      <td>53b7f855d4891e19</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=53b7f855d4891e19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ASSURANT</td>\n",
       "      <td>3+ years of relevant experience in analytics, ...</td>\n",
       "      <td>9ecd8095dd0355f8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=9ecd8095dd0355f8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>360i</td>\n",
       "      <td>The Associate Data Scientist will be mentored ...</td>\n",
       "      <td>c2b6dcbcb0895072</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=c2b6dcbcb0895072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Whether we are protecting the American people ...</td>\n",
       "      <td>40d8215afa28f4bb</td>\n",
       "      <td>HEALTH SCIENTIST</td>\n",
       "      <td>4.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=40d8215afa28f4bb</td>\n",
       "      <td>88305.0</td>\n",
       "      <td>114802.0</td>\n",
       "      <td>101553.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Vesta Corporation</td>\n",
       "      <td>Or PhD in Computer Science, Statistics, Applie...</td>\n",
       "      <td>24cec20de39398ca</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=24cec20de39398ca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Cox Automotive</td>\n",
       "      <td>Interprets problems and develops solutions to ...</td>\n",
       "      <td>4dd0428a36b610d7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=4dd0428a36b610d7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ASSURANT</td>\n",
       "      <td>The primary objective of this position is to e...</td>\n",
       "      <td>ed7467a761020f51</td>\n",
       "      <td>Sr Data Scientist - Fraud</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=ed7467a761020f51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Ga. Dept. of Admin. Services</td>\n",
       "      <td>SQL Server knowledge for developing queries an...</td>\n",
       "      <td>134c301ec3ba87c4</td>\n",
       "      <td>Statistical Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=134c301ec3ba87c4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>State Farm Mutual Automobile Insurance Company</td>\n",
       "      <td>Academic background in quantitative discipline...</td>\n",
       "      <td>594e039f37d4ec5d</td>\n",
       "      <td>Research Statistician</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=594e039f37d4ec5d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Data modeling, mining, pattern analysis, data ...</td>\n",
       "      <td>9b253c3eeae5f37a</td>\n",
       "      <td>Analytics Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=9b253c3eeae5f37a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Google</td>\n",
       "      <td>The Google Cloud training team already develop...</td>\n",
       "      <td>b96291bcf9c19e0a</td>\n",
       "      <td>Cloud Instructor (Big Data, Machine Learning),...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=b96291bcf9c19e0a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Travelport</td>\n",
       "      <td>Developing and implementing advanced analytics...</td>\n",
       "      <td>324aa9db249c02a7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=324aa9db249c02a7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Kabbage</td>\n",
       "      <td>As a part of the Data Science team, you will d...</td>\n",
       "      <td>6e3ccea1c8472429</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=6e3ccea1c8472429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>3 years of experience in data mining and stati...</td>\n",
       "      <td>07d2ec530def558d</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>3.5</td>\n",
       "      <td>20594.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=07d2ec530def558d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>360i</td>\n",
       "      <td>Data Scientist will work directly with 360i cl...</td>\n",
       "      <td>abb5e77d57d05bfb</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=abb5e77d57d05bfb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>eHire, LLC</td>\n",
       "      <td>Strong background in applying statistical mach...</td>\n",
       "      <td>f0341f282e4dc253</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f0341f282e4dc253</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Bastille</td>\n",
       "      <td>Position Bastille is seeking badass Data Scien...</td>\n",
       "      <td>f5d182f58df6fd06</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f5d182f58df6fd06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Master’s degree in Computer Science, Mathemati...</td>\n",
       "      <td>3ab193931df8ad50</td>\n",
       "      <td>Sr Data Scientist - Atlanta, GA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=3ab193931df8ad50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Georgia Tech Research Institute</td>\n",
       "      <td>The Georgia Tech Research Institute's Machine ...</td>\n",
       "      <td>0b18bd331be1a5ca</td>\n",
       "      <td>Machine Learning-Data Science Computer Vision ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=0b18bd331be1a5ca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Whether we are protecting the American people ...</td>\n",
       "      <td>ece367560a42bf9b</td>\n",
       "      <td>Health Scientist (Informatics)</td>\n",
       "      <td>4.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=ece367560a42bf9b</td>\n",
       "      <td>104349.0</td>\n",
       "      <td>135656.0</td>\n",
       "      <td>120002.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>HD Supply</td>\n",
       "      <td>Responsible for modeling complex enterprise pr...</td>\n",
       "      <td>5e4122b4e399341b</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>489.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=5e4122b4e399341b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Stackfolio</td>\n",
       "      <td>A competitive full-time salary as well as a gr...</td>\n",
       "      <td>be3a7444db34e9a3</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=be3a7444db34e9a3</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Machine learning, data visualization, statisti...</td>\n",
       "      <td>57dc2330cb3ed3c0</td>\n",
       "      <td>Sr Associate - Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=57dc2330cb3ed3c0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>SunTrust</td>\n",
       "      <td>Performs sophisticated data analytics (encompa...</td>\n",
       "      <td>16b342fb19d2cf92</td>\n",
       "      <td>Consumer Banking Data Scientist - Atlanta, GA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=16b342fb19d2cf92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>krg technology inc</td>\n",
       "      <td>Data scientist with either a Masters or PhD. S...</td>\n",
       "      <td>c033d176ea5a13bf</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=c033d176ea5a13bf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Apply machine learning and statistical techniq...</td>\n",
       "      <td>2eeab08cd59a3296</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11112.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=2eeab08cd59a3296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>GE Power</td>\n",
       "      <td>Architects, Data Scientists, Businesses and Pr...</td>\n",
       "      <td>3cd633102b36edc1</td>\n",
       "      <td>Staff Analytics Engineer – Installed Base</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=3cd633102b36edc1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NIIT Technologies</td>\n",
       "      <td>Expertise in operations research, applied stat...</td>\n",
       "      <td>42835cf45915a966</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>122.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=42835cf45915a966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Feedzai</td>\n",
       "      <td>Implement Feedzai's machine learning algorithm...</td>\n",
       "      <td>241bf43cfe61f5c0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=241bf43cfe61f5c0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Support and mentor data scientists. Master’s d...</td>\n",
       "      <td>78f1a9a1e62191ef</td>\n",
       "      <td>Principal Data Scientist - Atlanta, GA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2016-10-17 00:20:29.507371</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=78f1a9a1e62191ef</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13108</th>\n",
       "      <td>970.0</td>\n",
       "      <td>970</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>LeanTaas</td>\n",
       "      <td>LeanTaaS is looking for extraordinary data sci...</td>\n",
       "      <td>5d731bfd520450cd</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=5d731bfd520450cd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13109</th>\n",
       "      <td>971.0</td>\n",
       "      <td>971</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Averity</td>\n",
       "      <td>Enabling our Data Scientists to create product...</td>\n",
       "      <td>65ec1f25972d992b</td>\n",
       "      <td>Executive Director of Data Engineering (Media)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=65ec1f25972d992b</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13110</th>\n",
       "      <td>972.0</td>\n",
       "      <td>972</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>Cognosante, LLC</td>\n",
       "      <td>Cognosante is looking for a few talented data ...</td>\n",
       "      <td>8d1e1f06592788ab</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=8d1e1f06592788ab</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13111</th>\n",
       "      <td>973.0</td>\n",
       "      <td>973</td>\n",
       "      <td>Carlsbad, CA</td>\n",
       "      <td>CDM Technology</td>\n",
       "      <td>You like the idea of partnering with scientist...</td>\n",
       "      <td>f7b51f642226d60c</td>\n",
       "      <td>Java/Python Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f7b51f642226d60c</td>\n",
       "      <td>124800.0</td>\n",
       "      <td>124800.0</td>\n",
       "      <td>124800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13112</th>\n",
       "      <td>974.0</td>\n",
       "      <td>974</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>Health Fidelity</td>\n",
       "      <td>Using groundbreaking NLP and analytics technol...</td>\n",
       "      <td>d7b8192c8ed6599f</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=d7b8192c8ed6599f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13113</th>\n",
       "      <td>975.0</td>\n",
       "      <td>975</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NBA</td>\n",
       "      <td>Deep bench and experience in leading data scie...</td>\n",
       "      <td>95d2ca6db8e5c267</td>\n",
       "      <td>Senior Director, Data Intelligence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=95d2ca6db8e5c267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>976.0</td>\n",
       "      <td>976</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>MD Anderson Cancer Center</td>\n",
       "      <td>The primary purpose of the Research Statistica...</td>\n",
       "      <td>c3d60a2a43db94fe</td>\n",
       "      <td>Research Statistical Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=c3d60a2a43db94fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13115</th>\n",
       "      <td>977.0</td>\n",
       "      <td>977</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>automotiveMastermind Inc.</td>\n",
       "      <td>An MS/PhD program in Statistics, Mathematics, ...</td>\n",
       "      <td>2d12ad4b56eb3cb8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=2d12ad4b56eb3cb8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13116</th>\n",
       "      <td>978.0</td>\n",
       "      <td>978</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Analytic Partners</td>\n",
       "      <td>Lead/assist in methodology research and soluti...</td>\n",
       "      <td>d156a798af051399</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=d156a798af051399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13117</th>\n",
       "      <td>979.0</td>\n",
       "      <td>979</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Posh Technologies</td>\n",
       "      <td>Design and build new data set processes for mo...</td>\n",
       "      <td>11cf38718f8c5eec</td>\n",
       "      <td>Data Scientist(Position5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=11cf38718f8c5eec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>980.0</td>\n",
       "      <td>980</td>\n",
       "      <td>Hershey, PA</td>\n",
       "      <td>Hershey</td>\n",
       "      <td>8+ years experience in Statistics, Machine Lea...</td>\n",
       "      <td>88b5434ff5ebee2c</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>308.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=88b5434ff5ebee2c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13119</th>\n",
       "      <td>981.0</td>\n",
       "      <td>981</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>Today, PHL responds to essential and emergency...</td>\n",
       "      <td>f94515b4ae33dd47</td>\n",
       "      <td>Senior Laboratory Data Analyst, Bureau of the ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f94515b4ae33dd47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13120</th>\n",
       "      <td>982.0</td>\n",
       "      <td>982</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Correlation One</td>\n",
       "      <td>We are a science-driven systematic trading fir...</td>\n",
       "      <td>d3afe33484d088a4</td>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=d3afe33484d088a4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13121</th>\n",
       "      <td>983.0</td>\n",
       "      <td>983</td>\n",
       "      <td>Westchester, NY</td>\n",
       "      <td>L.J. Gonzer Associates</td>\n",
       "      <td>Data analysis and interpretation. Preparing ma...</td>\n",
       "      <td>0640e5d08d73f155</td>\n",
       "      <td>Ph.D Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=0640e5d08d73f155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13122</th>\n",
       "      <td>984.0</td>\n",
       "      <td>984</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Rockstar New York</td>\n",
       "      <td>Serve as a subject matter expert to the securi...</td>\n",
       "      <td>0e486be090f66c4e</td>\n",
       "      <td>Security Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=0e486be090f66c4e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>985.0</td>\n",
       "      <td>985</td>\n",
       "      <td>Clayton, MO</td>\n",
       "      <td>Business Intelligence-Finance</td>\n",
       "      <td>Master’s degree in Statistics, Mathematics, Co...</td>\n",
       "      <td>46cdbbd2f5a93a98</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=46cdbbd2f5a93a98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13124</th>\n",
       "      <td>986.0</td>\n",
       "      <td>986</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>PNS IT Solutions LLC</td>\n",
       "      <td>Leadership of the team involves direct managem...</td>\n",
       "      <td>0cb4527a47b567d7</td>\n",
       "      <td>Data Scientist / Data Modeling / Data Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=0cb4527a47b567d7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13125</th>\n",
       "      <td>987.0</td>\n",
       "      <td>987</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HERE</td>\n",
       "      <td>Data mining, machine learning, and optimizatio...</td>\n",
       "      <td>1636eef60b3362f7</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=1636eef60b3362f7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13126</th>\n",
       "      <td>988.0</td>\n",
       "      <td>988</td>\n",
       "      <td>Pleasanton, CA</td>\n",
       "      <td>10X Genomics</td>\n",
       "      <td>Deep understanding of the NGS applications spa...</td>\n",
       "      <td>50a2e75ed126754e</td>\n",
       "      <td>Applications Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=50a2e75ed126754e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13127</th>\n",
       "      <td>989.0</td>\n",
       "      <td>989</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>BioPoint</td>\n",
       "      <td>Strong statistical quantitative skills, includ...</td>\n",
       "      <td>8e3b71a666945af0</td>\n",
       "      <td>Outcomes Research Statistician (8480)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=8e3b71a666945af0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13128</th>\n",
       "      <td>990.0</td>\n",
       "      <td>990</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Adaptive Biotechnologies</td>\n",
       "      <td>Maintain and establish good working relationsh...</td>\n",
       "      <td>f9957b82b86276f7</td>\n",
       "      <td>Biostatistician</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f9957b82b86276f7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13129</th>\n",
       "      <td>991.0</td>\n",
       "      <td>991</td>\n",
       "      <td>Research Triangle Park, NC</td>\n",
       "      <td>SciMetrika</td>\n",
       "      <td>ScitoVation scientist have earned a reputation...</td>\n",
       "      <td>5a6bca92e8012c2a</td>\n",
       "      <td>Statistical Modeler</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=5a6bca92e8012c2a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13130</th>\n",
       "      <td>992.0</td>\n",
       "      <td>992</td>\n",
       "      <td>Medford, MA</td>\n",
       "      <td>Agero, Inc.</td>\n",
       "      <td>5 years of experience building and applying so...</td>\n",
       "      <td>cb8cea591851c2a5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=cb8cea591851c2a5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>993.0</td>\n",
       "      <td>993</td>\n",
       "      <td>Carmel, IN</td>\n",
       "      <td>Adesa Inc.</td>\n",
       "      <td>Data access by data scientists and the mainten...</td>\n",
       "      <td>14777a837760f869</td>\n",
       "      <td>Data Science Arhitect</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=14777a837760f869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13132</th>\n",
       "      <td>994.0</td>\n",
       "      <td>994</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>Lab Support</td>\n",
       "      <td>Ability to identify aberrant/out of spec data ...</td>\n",
       "      <td>664005e69d87418a</td>\n",
       "      <td>Associate Scientist- Data Review</td>\n",
       "      <td>3.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=664005e69d87418a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13133</th>\n",
       "      <td>995.0</td>\n",
       "      <td>995</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>General Mills</td>\n",
       "      <td>Comfortable in basic statistical analysis, mod...</td>\n",
       "      <td>7b3a98f4ccc83b68</td>\n",
       "      <td>Data Scientist - Global Business Solutions</td>\n",
       "      <td>4.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=7b3a98f4ccc83b68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13134</th>\n",
       "      <td>996.0</td>\n",
       "      <td>996</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>eHire, LLC</td>\n",
       "      <td>Strong background in applying statistical mach...</td>\n",
       "      <td>f0341f282e4dc253</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=f0341f282e4dc253</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>997.0</td>\n",
       "      <td>997</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Elite WorkForce, Inc</td>\n",
       "      <td>Senior Data Scientist Location:. Data Scientis...</td>\n",
       "      <td>cad4d0671d1752c3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=cad4d0671d1752c3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>998.0</td>\n",
       "      <td>998</td>\n",
       "      <td>Michigan,</td>\n",
       "      <td>Sparrow Health System</td>\n",
       "      <td>Work with and assist Sparrow Graduate Medical ...</td>\n",
       "      <td>8a102fe16026588b</td>\n",
       "      <td>SCRI-RESEARCH DATA ANALYST</td>\n",
       "      <td>3.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=8a102fe16026588b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>999.0</td>\n",
       "      <td>999</td>\n",
       "      <td>Santa Clara Valley, CA</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Experience with machine learning tools and lib...</td>\n",
       "      <td>269a60a59d86d234</td>\n",
       "      <td>Data Scientist - Maps POI</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2016-10-17 00:12:22.949204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=269a60a59d86d234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13138 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Unnamed: 0.1                    location  \\\n",
       "0             0.0            0                 Atlanta, GA   \n",
       "1             1.0            1                 Atlanta, GA   \n",
       "2             2.0            2                 Atlanta, GA   \n",
       "3             3.0            3                 Atlanta, GA   \n",
       "4             4.0            4                 Atlanta, GA   \n",
       "5             5.0            5                 Atlanta, GA   \n",
       "6             6.0            6                 Atlanta, GA   \n",
       "7             7.0            7                 Atlanta, GA   \n",
       "8             8.0            8                 Atlanta, GA   \n",
       "9             9.0            9                 Atlanta, GA   \n",
       "10           10.0           10                 Atlanta, GA   \n",
       "11           11.0           11                 Atlanta, GA   \n",
       "12           12.0           12                 Atlanta, GA   \n",
       "13           13.0           13                 Atlanta, GA   \n",
       "14           14.0           14                 Atlanta, GA   \n",
       "15           15.0           15                 Atlanta, GA   \n",
       "16           16.0           16                 Atlanta, GA   \n",
       "17           17.0           17                 Atlanta, GA   \n",
       "18           18.0           18                 Atlanta, GA   \n",
       "19           19.0           19                 Atlanta, GA   \n",
       "20           20.0           20                 Atlanta, GA   \n",
       "21           21.0           21                 Atlanta, GA   \n",
       "22           22.0           22                 Atlanta, GA   \n",
       "23           23.0           23                 Atlanta, GA   \n",
       "24           24.0           24              Alpharetta, GA   \n",
       "25           25.0           25              Alpharetta, GA   \n",
       "26           26.0           26                 Atlanta, GA   \n",
       "27           27.0           27                 Atlanta, GA   \n",
       "28           28.0           28                 Atlanta, GA   \n",
       "29           29.0           29                 Atlanta, GA   \n",
       "...           ...          ...                         ...   \n",
       "13108       970.0          970             Santa Clara, CA   \n",
       "13109       971.0          971                New York, NY   \n",
       "13110       972.0          972                  McLean, VA   \n",
       "13111       973.0          973                Carlsbad, CA   \n",
       "13112       974.0          974              Pittsburgh, PA   \n",
       "13113       975.0          975                New York, NY   \n",
       "13114       976.0          976                 Houston, TX   \n",
       "13115       977.0          977                New York, NY   \n",
       "13116       978.0          978                New York, NY   \n",
       "13117       979.0          979                 Redmond, WA   \n",
       "13118       980.0          980                 Hershey, PA   \n",
       "13119       981.0          981               Manhattan, NY   \n",
       "13120       982.0          982                New York, NY   \n",
       "13121       983.0          983             Westchester, NY   \n",
       "13122       984.0          984                New York, NY   \n",
       "13123       985.0          985                 Clayton, MO   \n",
       "13124       986.0          986                Hartford, CT   \n",
       "13125       987.0          987                 Chicago, IL   \n",
       "13126       988.0          988              Pleasanton, CA   \n",
       "13127       989.0          989               Cambridge, MA   \n",
       "13128       990.0          990                 Seattle, WA   \n",
       "13129       991.0          991  Research Triangle Park, NC   \n",
       "13130       992.0          992                 Medford, MA   \n",
       "13131       993.0          993                  Carmel, IN   \n",
       "13132       994.0          994             Morrisville, NC   \n",
       "13133       995.0          995             Minneapolis, MN   \n",
       "13134       996.0          996                 Atlanta, GA   \n",
       "13135       997.0          997                   Tampa, FL   \n",
       "13136       998.0          998                  Michigan,    \n",
       "13137       999.0          999      Santa Clara Valley, CA   \n",
       "\n",
       "                                              company  \\\n",
       "0                                                KPMG   \n",
       "1                                            ASSURANT   \n",
       "2                                                360i   \n",
       "3          Centers for Disease Control and Prevention   \n",
       "4                                   Vesta Corporation   \n",
       "5                                      Cox Automotive   \n",
       "6                                            ASSURANT   \n",
       "7                        Ga. Dept. of Admin. Services   \n",
       "8      State Farm Mutual Automobile Insurance Company   \n",
       "9                                           Honeywell   \n",
       "10                                             Google   \n",
       "11                                         Travelport   \n",
       "12                                            Kabbage   \n",
       "13                                         Home Depot   \n",
       "14                                               360i   \n",
       "15                                         eHire, LLC   \n",
       "16                                           Bastille   \n",
       "17                                          Honeywell   \n",
       "18                    Georgia Tech Research Institute   \n",
       "19         Centers for Disease Control and Prevention   \n",
       "20                                          HD Supply   \n",
       "21                                         Stackfolio   \n",
       "22                                               KPMG   \n",
       "23                                           SunTrust   \n",
       "24                                 krg technology inc   \n",
       "25                                            Verizon   \n",
       "26                                           GE Power   \n",
       "27                                  NIIT Technologies   \n",
       "28                                            Feedzai   \n",
       "29                                          Honeywell   \n",
       "...                                               ...   \n",
       "13108                                        LeanTaas   \n",
       "13109                                         Averity   \n",
       "13110                                 Cognosante, LLC   \n",
       "13111                                  CDM Technology   \n",
       "13112                                 Health Fidelity   \n",
       "13113                                             NBA   \n",
       "13114                       MD Anderson Cancer Center   \n",
       "13115                       automotiveMastermind Inc.   \n",
       "13116                               Analytic Partners   \n",
       "13117                               Posh Technologies   \n",
       "13118                                         Hershey   \n",
       "13119                   DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "13120                                 Correlation One   \n",
       "13121                          L.J. Gonzer Associates   \n",
       "13122                               Rockstar New York   \n",
       "13123                   Business Intelligence-Finance   \n",
       "13124                            PNS IT Solutions LLC   \n",
       "13125                                            HERE   \n",
       "13126                                    10X Genomics   \n",
       "13127                                        BioPoint   \n",
       "13128                        Adaptive Biotechnologies   \n",
       "13129                                      SciMetrika   \n",
       "13130                                     Agero, Inc.   \n",
       "13131                                      Adesa Inc.   \n",
       "13132                                     Lab Support   \n",
       "13133                                   General Mills   \n",
       "13134                                      eHire, LLC   \n",
       "13135                            Elite WorkForce, Inc   \n",
       "13136                           Sparrow Health System   \n",
       "13137                                           Apple   \n",
       "\n",
       "                                                 summary              jkid  \\\n",
       "0      Machine learning, data visualization, statisti...  53b7f855d4891e19   \n",
       "1      3+ years of relevant experience in analytics, ...  9ecd8095dd0355f8   \n",
       "2      The Associate Data Scientist will be mentored ...  c2b6dcbcb0895072   \n",
       "3      Whether we are protecting the American people ...  40d8215afa28f4bb   \n",
       "4      Or PhD in Computer Science, Statistics, Applie...  24cec20de39398ca   \n",
       "5      Interprets problems and develops solutions to ...  4dd0428a36b610d7   \n",
       "6      The primary objective of this position is to e...  ed7467a761020f51   \n",
       "7      SQL Server knowledge for developing queries an...  134c301ec3ba87c4   \n",
       "8      Academic background in quantitative discipline...  594e039f37d4ec5d   \n",
       "9      Data modeling, mining, pattern analysis, data ...  9b253c3eeae5f37a   \n",
       "10     The Google Cloud training team already develop...  b96291bcf9c19e0a   \n",
       "11     Developing and implementing advanced analytics...  324aa9db249c02a7   \n",
       "12     As a part of the Data Science team, you will d...  6e3ccea1c8472429   \n",
       "13     3 years of experience in data mining and stati...  07d2ec530def558d   \n",
       "14     Data Scientist will work directly with 360i cl...  abb5e77d57d05bfb   \n",
       "15     Strong background in applying statistical mach...  f0341f282e4dc253   \n",
       "16     Position Bastille is seeking badass Data Scien...  f5d182f58df6fd06   \n",
       "17     Master’s degree in Computer Science, Mathemati...  3ab193931df8ad50   \n",
       "18     The Georgia Tech Research Institute's Machine ...  0b18bd331be1a5ca   \n",
       "19     Whether we are protecting the American people ...  ece367560a42bf9b   \n",
       "20     Responsible for modeling complex enterprise pr...  5e4122b4e399341b   \n",
       "21     A competitive full-time salary as well as a gr...  be3a7444db34e9a3   \n",
       "22     Machine learning, data visualization, statisti...  57dc2330cb3ed3c0   \n",
       "23     Performs sophisticated data analytics (encompa...  16b342fb19d2cf92   \n",
       "24     Data scientist with either a Masters or PhD. S...  c033d176ea5a13bf   \n",
       "25     Apply machine learning and statistical techniq...  2eeab08cd59a3296   \n",
       "26     Architects, Data Scientists, Businesses and Pr...  3cd633102b36edc1   \n",
       "27     Expertise in operations research, applied stat...  42835cf45915a966   \n",
       "28     Implement Feedzai's machine learning algorithm...  241bf43cfe61f5c0   \n",
       "29     Support and mentor data scientists. Master’s d...  78f1a9a1e62191ef   \n",
       "...                                                  ...               ...   \n",
       "13108  LeanTaaS is looking for extraordinary data sci...  5d731bfd520450cd   \n",
       "13109  Enabling our Data Scientists to create product...  65ec1f25972d992b   \n",
       "13110  Cognosante is looking for a few talented data ...  8d1e1f06592788ab   \n",
       "13111  You like the idea of partnering with scientist...  f7b51f642226d60c   \n",
       "13112  Using groundbreaking NLP and analytics technol...  d7b8192c8ed6599f   \n",
       "13113  Deep bench and experience in leading data scie...  95d2ca6db8e5c267   \n",
       "13114  The primary purpose of the Research Statistica...  c3d60a2a43db94fe   \n",
       "13115  An MS/PhD program in Statistics, Mathematics, ...  2d12ad4b56eb3cb8   \n",
       "13116  Lead/assist in methodology research and soluti...  d156a798af051399   \n",
       "13117  Design and build new data set processes for mo...  11cf38718f8c5eec   \n",
       "13118  8+ years experience in Statistics, Machine Lea...  88b5434ff5ebee2c   \n",
       "13119  Today, PHL responds to essential and emergency...  f94515b4ae33dd47   \n",
       "13120  We are a science-driven systematic trading fir...  d3afe33484d088a4   \n",
       "13121  Data analysis and interpretation. Preparing ma...  0640e5d08d73f155   \n",
       "13122  Serve as a subject matter expert to the securi...  0e486be090f66c4e   \n",
       "13123  Master’s degree in Statistics, Mathematics, Co...  46cdbbd2f5a93a98   \n",
       "13124  Leadership of the team involves direct managem...  0cb4527a47b567d7   \n",
       "13125  Data mining, machine learning, and optimizatio...  1636eef60b3362f7   \n",
       "13126  Deep understanding of the NGS applications spa...  50a2e75ed126754e   \n",
       "13127  Strong statistical quantitative skills, includ...  8e3b71a666945af0   \n",
       "13128  Maintain and establish good working relationsh...  f9957b82b86276f7   \n",
       "13129  ScitoVation scientist have earned a reputation...  5a6bca92e8012c2a   \n",
       "13130  5 years of experience building and applying so...  cb8cea591851c2a5   \n",
       "13131  Data access by data scientists and the mainten...  14777a837760f869   \n",
       "13132  Ability to identify aberrant/out of spec data ...  664005e69d87418a   \n",
       "13133  Comfortable in basic statistical analysis, mod...  7b3a98f4ccc83b68   \n",
       "13134  Strong background in applying statistical mach...  f0341f282e4dc253   \n",
       "13135  Senior Data Scientist Location:. Data Scientis...  cad4d0671d1752c3   \n",
       "13136  Work with and assist Sparrow Graduate Medical ...  8a102fe16026588b   \n",
       "13137  Experience with machine learning tools and lib...  269a60a59d86d234   \n",
       "\n",
       "                                                   title  stars  reviews  \\\n",
       "0                                         Data Scientist    4.0   1768.0   \n",
       "1                                         Data Scientist    3.5   1107.0   \n",
       "2                               Associate Data Scientist    4.0      9.0   \n",
       "3                                       HEALTH SCIENTIST    4.5     64.0   \n",
       "4                                  Senior Data Scientist    3.0     31.0   \n",
       "5                                         Data Scientist    3.0     42.0   \n",
       "6                              Sr Data Scientist - Fraud    3.5   1107.0   \n",
       "7                               Statistical Data Analyst    NaN      0.0   \n",
       "8                                  Research Statistician    4.0   3358.0   \n",
       "9                               Analytics Data Scientist    3.5   3474.0   \n",
       "10     Cloud Instructor (Big Data, Machine Learning),...    4.0   1218.0   \n",
       "11                                        Data Scientist    4.0     52.0   \n",
       "12                                        Data Scientist    NaN      0.0   \n",
       "13                                        DATA SCIENTIST    3.5  20594.0   \n",
       "14                                     Sr Data Scientist    4.0      9.0   \n",
       "15                                     Sr Data Scientist    NaN      0.0   \n",
       "16                                        Data Scientist    NaN      0.0   \n",
       "17                       Sr Data Scientist - Atlanta, GA    3.5   3474.0   \n",
       "18     Machine Learning-Data Science Computer Vision ...    4.0    255.0   \n",
       "19                        Health Scientist (Informatics)    4.5     64.0   \n",
       "20                                        Data Scientist    3.5    489.0   \n",
       "21                                   Lead Data Scientist    NaN      0.0   \n",
       "22                         Sr Associate - Data Scientist    4.0   1768.0   \n",
       "23         Consumer Banking Data Scientist - Atlanta, GA    3.5   2101.0   \n",
       "24                                        Data Scientist    NaN      0.0   \n",
       "25                                 Senior Data Scientist    3.5  11112.0   \n",
       "26             Staff Analytics Engineer – Installed Base    4.0    153.0   \n",
       "27                                        Data Scientist    3.5    122.0   \n",
       "28                                        Data Scientist    NaN      0.0   \n",
       "29                Principal Data Scientist - Atlanta, GA    3.5   3474.0   \n",
       "...                                                  ...    ...      ...   \n",
       "13108                              Senior Data Scientist    NaN      0.0   \n",
       "13109     Executive Director of Data Engineering (Media)    NaN      0.0   \n",
       "13110                                Data Analyst Intern    3.5     14.0   \n",
       "13111                      Java/Python Software Engineer    NaN      0.0   \n",
       "13112                                     Data Scientist    NaN      0.0   \n",
       "13113                 Senior Director, Data Intelligence    4.0     20.0   \n",
       "13114                       Research Statistical Analyst    4.0    250.0   \n",
       "13115                                     Data Scientist    NaN      0.0   \n",
       "13116                                     Data Scientist    NaN      0.0   \n",
       "13117                          Data Scientist(Position5)    NaN      0.0   \n",
       "13118                                     Data Scientist    3.5    308.0   \n",
       "13119  Senior Laboratory Data Analyst, Bureau of the ...    4.0      5.0   \n",
       "13120                      Quantitative Research Analyst    NaN      0.0   \n",
       "13121                                Ph.D Data Scientist    3.5      2.0   \n",
       "13122                            Security Data Scientist    NaN      0.0   \n",
       "13123                                   Data Scientist I    NaN      0.0   \n",
       "13124     Data Scientist / Data Modeling / Data Engineer    NaN      0.0   \n",
       "13125                           Principal Data Scientist    3.5     56.0   \n",
       "13126                          Applications Data Analyst    NaN      0.0   \n",
       "13127              Outcomes Research Statistician (8480)    NaN      0.0   \n",
       "13128                                    Biostatistician    NaN      0.0   \n",
       "13129                                Statistical Modeler    4.0      3.0   \n",
       "13130                                     Data Scientist    NaN      0.0   \n",
       "13131                              Data Science Arhitect    3.0    205.0   \n",
       "13132                   Associate Scientist- Data Review    3.5     55.0   \n",
       "13133         Data Scientist - Global Business Solutions    4.0    559.0   \n",
       "13134                                  Sr Data Scientist    NaN      0.0   \n",
       "13135                              Senior Data Scientist    NaN      0.0   \n",
       "13136                         SCRI-RESEARCH DATA ANALYST    3.5     56.0   \n",
       "13137                          Data Scientist - Maps POI    4.0   2570.0   \n",
       "\n",
       "       post_date_daysAgo                   pull_date search_city  \\\n",
       "0               2.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "1              10.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "2              11.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "3               1.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "4               9.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "5              12.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "6               1.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "7               5.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "8               3.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "9              10.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "10              3.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "11             30.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "12             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "13             29.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "14             19.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "15             16.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "16             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "17             24.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "18             11.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "19              2.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "20             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "21             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "22             24.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "23             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "24             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "25             19.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "26             13.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "27             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "28             45.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "29             24.000000  2016-10-17 00:20:29.507371     Atlanta   \n",
       "...                  ...                         ...         ...   \n",
       "13108          16.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13109           4.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13110           0.041667  2016-10-17 00:12:22.949204         NaN   \n",
       "13111           4.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13112          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13113          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13114          30.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13115          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13116          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13117          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13118          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13119          22.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13120          11.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13121          20.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13122          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13123          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13124          12.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13125          10.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13126          20.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13127           1.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13128          20.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13129           1.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13130          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13131          45.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13132           1.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13133          20.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13134          16.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13135          20.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13136          16.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "13137          22.000000  2016-10-17 00:12:22.949204         NaN   \n",
       "\n",
       "                                               job_link   sal_low  sal_high  \\\n",
       "0      http://www.indeed.com/rc/clk?jk=53b7f855d4891e19       0.0       0.0   \n",
       "1      http://www.indeed.com/rc/clk?jk=9ecd8095dd0355f8       0.0       0.0   \n",
       "2      http://www.indeed.com/rc/clk?jk=c2b6dcbcb0895072       0.0       0.0   \n",
       "3      http://www.indeed.com/rc/clk?jk=40d8215afa28f4bb   88305.0  114802.0   \n",
       "4      http://www.indeed.com/rc/clk?jk=24cec20de39398ca       0.0       0.0   \n",
       "5      http://www.indeed.com/rc/clk?jk=4dd0428a36b610d7       0.0       0.0   \n",
       "6      http://www.indeed.com/rc/clk?jk=ed7467a761020f51       0.0       0.0   \n",
       "7      http://www.indeed.com/rc/clk?jk=134c301ec3ba87c4       0.0       0.0   \n",
       "8      http://www.indeed.com/rc/clk?jk=594e039f37d4ec5d       0.0       0.0   \n",
       "9      http://www.indeed.com/rc/clk?jk=9b253c3eeae5f37a       0.0       0.0   \n",
       "10     http://www.indeed.com/rc/clk?jk=b96291bcf9c19e0a       0.0       0.0   \n",
       "11     http://www.indeed.com/rc/clk?jk=324aa9db249c02a7       0.0       0.0   \n",
       "12     http://www.indeed.com/rc/clk?jk=6e3ccea1c8472429       0.0       0.0   \n",
       "13     http://www.indeed.com/rc/clk?jk=07d2ec530def558d       0.0       0.0   \n",
       "14     http://www.indeed.com/rc/clk?jk=abb5e77d57d05bfb       0.0       0.0   \n",
       "15     http://www.indeed.com/rc/clk?jk=f0341f282e4dc253  150000.0  150000.0   \n",
       "16     http://www.indeed.com/rc/clk?jk=f5d182f58df6fd06       0.0       0.0   \n",
       "17     http://www.indeed.com/rc/clk?jk=3ab193931df8ad50       0.0       0.0   \n",
       "18     http://www.indeed.com/rc/clk?jk=0b18bd331be1a5ca       0.0       0.0   \n",
       "19     http://www.indeed.com/rc/clk?jk=ece367560a42bf9b  104349.0  135656.0   \n",
       "20     http://www.indeed.com/rc/clk?jk=5e4122b4e399341b       0.0       0.0   \n",
       "21     http://www.indeed.com/rc/clk?jk=be3a7444db34e9a3   80000.0   80000.0   \n",
       "22     http://www.indeed.com/rc/clk?jk=57dc2330cb3ed3c0       0.0       0.0   \n",
       "23     http://www.indeed.com/rc/clk?jk=16b342fb19d2cf92       0.0       0.0   \n",
       "24     http://www.indeed.com/rc/clk?jk=c033d176ea5a13bf       0.0       0.0   \n",
       "25     http://www.indeed.com/rc/clk?jk=2eeab08cd59a3296       0.0       0.0   \n",
       "26     http://www.indeed.com/rc/clk?jk=3cd633102b36edc1       0.0       0.0   \n",
       "27     http://www.indeed.com/rc/clk?jk=42835cf45915a966       0.0       0.0   \n",
       "28     http://www.indeed.com/rc/clk?jk=241bf43cfe61f5c0       0.0       0.0   \n",
       "29     http://www.indeed.com/rc/clk?jk=78f1a9a1e62191ef       0.0       0.0   \n",
       "...                                                 ...       ...       ...   \n",
       "13108  http://www.indeed.com/rc/clk?jk=5d731bfd520450cd       0.0       0.0   \n",
       "13109  http://www.indeed.com/rc/clk?jk=65ec1f25972d992b  200000.0  230000.0   \n",
       "13110  http://www.indeed.com/rc/clk?jk=8d1e1f06592788ab       0.0       0.0   \n",
       "13111  http://www.indeed.com/rc/clk?jk=f7b51f642226d60c  124800.0  124800.0   \n",
       "13112  http://www.indeed.com/rc/clk?jk=d7b8192c8ed6599f       0.0       0.0   \n",
       "13113  http://www.indeed.com/rc/clk?jk=95d2ca6db8e5c267       0.0       0.0   \n",
       "13114  http://www.indeed.com/rc/clk?jk=c3d60a2a43db94fe       0.0       0.0   \n",
       "13115  http://www.indeed.com/rc/clk?jk=2d12ad4b56eb3cb8       0.0       0.0   \n",
       "13116  http://www.indeed.com/rc/clk?jk=d156a798af051399       0.0       0.0   \n",
       "13117  http://www.indeed.com/rc/clk?jk=11cf38718f8c5eec       0.0       0.0   \n",
       "13118  http://www.indeed.com/rc/clk?jk=88b5434ff5ebee2c       0.0       0.0   \n",
       "13119  http://www.indeed.com/rc/clk?jk=f94515b4ae33dd47       0.0       0.0   \n",
       "13120  http://www.indeed.com/rc/clk?jk=d3afe33484d088a4       0.0       0.0   \n",
       "13121  http://www.indeed.com/rc/clk?jk=0640e5d08d73f155       0.0       0.0   \n",
       "13122  http://www.indeed.com/rc/clk?jk=0e486be090f66c4e       0.0       0.0   \n",
       "13123  http://www.indeed.com/rc/clk?jk=46cdbbd2f5a93a98       0.0       0.0   \n",
       "13124  http://www.indeed.com/rc/clk?jk=0cb4527a47b567d7       0.0       0.0   \n",
       "13125  http://www.indeed.com/rc/clk?jk=1636eef60b3362f7       0.0       0.0   \n",
       "13126  http://www.indeed.com/rc/clk?jk=50a2e75ed126754e       0.0       0.0   \n",
       "13127  http://www.indeed.com/rc/clk?jk=8e3b71a666945af0       0.0       0.0   \n",
       "13128  http://www.indeed.com/rc/clk?jk=f9957b82b86276f7       0.0       0.0   \n",
       "13129  http://www.indeed.com/rc/clk?jk=5a6bca92e8012c2a       0.0       0.0   \n",
       "13130  http://www.indeed.com/rc/clk?jk=cb8cea591851c2a5       0.0       0.0   \n",
       "13131  http://www.indeed.com/rc/clk?jk=14777a837760f869       0.0       0.0   \n",
       "13132  http://www.indeed.com/rc/clk?jk=664005e69d87418a       0.0       0.0   \n",
       "13133  http://www.indeed.com/rc/clk?jk=7b3a98f4ccc83b68       0.0       0.0   \n",
       "13134  http://www.indeed.com/rc/clk?jk=f0341f282e4dc253  150000.0  150000.0   \n",
       "13135  http://www.indeed.com/rc/clk?jk=cad4d0671d1752c3       0.0       0.0   \n",
       "13136  http://www.indeed.com/rc/clk?jk=8a102fe16026588b       0.0       0.0   \n",
       "13137  http://www.indeed.com/rc/clk?jk=269a60a59d86d234       0.0       0.0   \n",
       "\n",
       "        sal_avg   COL_new  \n",
       "0           0.0  1.502674  \n",
       "1           0.0  1.502674  \n",
       "2           0.0  1.502674  \n",
       "3      101553.0  1.502674  \n",
       "4           0.0  1.502674  \n",
       "5           0.0  1.502674  \n",
       "6           0.0  1.502674  \n",
       "7           0.0  1.502674  \n",
       "8           0.0  1.502674  \n",
       "9           0.0  1.502674  \n",
       "10          0.0  1.502674  \n",
       "11          0.0  1.502674  \n",
       "12          0.0  1.502674  \n",
       "13          0.0  1.502674  \n",
       "14          0.0  1.502674  \n",
       "15     150000.0  1.502674  \n",
       "16          0.0  1.502674  \n",
       "17          0.0  1.502674  \n",
       "18          0.0  1.502674  \n",
       "19     120002.0  1.502674  \n",
       "20          0.0  1.502674  \n",
       "21      80000.0  1.502674  \n",
       "22          0.0  1.502674  \n",
       "23          0.0  1.502674  \n",
       "24          0.0  1.502674  \n",
       "25          0.0  1.502674  \n",
       "26          0.0  1.502674  \n",
       "27          0.0  1.502674  \n",
       "28          0.0  1.502674  \n",
       "29          0.0  1.502674  \n",
       "...         ...       ...  \n",
       "13108       0.0       NaN  \n",
       "13109  215000.0       NaN  \n",
       "13110       0.0       NaN  \n",
       "13111  124800.0       NaN  \n",
       "13112       0.0       NaN  \n",
       "13113       0.0       NaN  \n",
       "13114       0.0       NaN  \n",
       "13115       0.0       NaN  \n",
       "13116       0.0       NaN  \n",
       "13117       0.0       NaN  \n",
       "13118       0.0       NaN  \n",
       "13119       0.0       NaN  \n",
       "13120       0.0       NaN  \n",
       "13121       0.0       NaN  \n",
       "13122       0.0       NaN  \n",
       "13123       0.0       NaN  \n",
       "13124       0.0       NaN  \n",
       "13125       0.0       NaN  \n",
       "13126       0.0       NaN  \n",
       "13127       0.0       NaN  \n",
       "13128       0.0       NaN  \n",
       "13129       0.0       NaN  \n",
       "13130       0.0       NaN  \n",
       "13131       0.0       NaN  \n",
       "13132       0.0       NaN  \n",
       "13133       0.0       NaN  \n",
       "13134  150000.0       NaN  \n",
       "13135       0.0       NaN  \n",
       "13136       0.0       NaN  \n",
       "13137       0.0       NaN  \n",
       "\n",
       "[13138 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL = pd.DataFrame([c, r]).T\n",
    "COL = COL.rename(columns = {0:'Cities',1:'price_index'})\n",
    "COL['Cities'] = COL['Cities'].apply(lambda x: str(x).split(',')).apply(lambda x: x[0]).apply(lambda x: str(x).replace(' (United States)',''))\n",
    "COL['price_index'] = COL['price_index'].astype(int)\n",
    "new_base  = COL.loc[0,'price_index']\n",
    "COL['COL_new'] = COL['price_index'].apply(lambda x: float(new_base)/x)\n",
    "COL.loc[16,'Cities'] = 'Minneapolis'\n",
    "COL.loc[2,'Cities'] = 'Washington, DC'\n",
    "COL.loc[0,'Cities'] = 'New York'\n",
    "print master_df.shape\n",
    "master_df = pd.merge(master_df,COL.iloc[:,[0,-1]], left_on='search_city',right_on='Cities',how='left')\n",
    "del master_df['Cities']\n",
    "\n",
    "master_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# lets delete the unnamed columns earlier\n",
    "\n",
    "# del master_df['Unnamed: 0']\n",
    "# del master_df['Unnamed: 0.1']\n",
    "# del master_df['COL_new_y']\n",
    "del master_df['COL_new_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to add more to filter out the titles from mid to senior or entry\n",
    "\n",
    "senior = ['sr','senior','lead','instructor','principal', 'director','manager','consultant']\n",
    "mid = []\n",
    "entry = ['associate','Associate','intern','junior','-1']\n",
    "senior_bin = []\n",
    "mid_bin = []\n",
    "entry_bin = []\n",
    "for x in master_df['title']:\n",
    "    if any(word in x.lower() for word in senior):\n",
    "        senior_bin.append(1)\n",
    "        mid_bin.append(0)\n",
    "        entry_bin.append(0)\n",
    "    elif any(word in x.lower() for word in entry):\n",
    "        senior_bin.append(0)\n",
    "        mid_bin.append(0)\n",
    "        entry_bin.append(1)\n",
    "    else:\n",
    "        senior_bin.append(0)\n",
    "        mid_bin.append(1)\n",
    "        entry_bin.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df['senior_bin'] = pd.Series(senior_bin)\n",
    "master_df['mid_bin'] = pd.Series(mid_bin)\n",
    "master_df['entry_bin'] = pd.Series(entry_bin)\n",
    "# for x in master_df[master_df['mid_bin'] == 1]['title'].unique():\n",
    "#     print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senior = ['sr','senior','lead','instructor','principal', 'director','manager','consultant','chief']\n",
    "mid = ['data','scientist','analyst','analytics','statistician',\"statistical\",'machine learning']\n",
    "entry = ['associate','Associate','intern','junior','-1']\n",
    "senior_bin = []\n",
    "mid_bin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senior = ['sr','senior','lead','instructor','principal', 'director','manager','consultant','chief']\n",
    "mid = ['data','scientist','analyst','analytics','statistician',\"statistical\",'machine learning']\n",
    "entry = ['associate','Associate','intern','junior','-1']\n",
    "senior_bin = []\n",
    "mid_bin = []\n",
    "entry_bin = []\n",
    "other_bin = []\n",
    "for x in master_df['title']:\n",
    "    if any(word in x.lower() for word in senior):\n",
    "        senior_bin.append(1)\n",
    "        mid_bin.append(0)\n",
    "        entry_bin.append(0)\n",
    "        other_bin.append(0)\n",
    "    elif any(word in x.lower() for word in entry):\n",
    "        senior_bin.append(0)\n",
    "        mid_bin.append(0)\n",
    "        entry_bin.append(1)\n",
    "        other_bin.append(0)        \n",
    "    elif any(word in x.lower() for word in mid):\n",
    "        senior_bin.append(0)\n",
    "        mid_bin.append(1)\n",
    "        entry_bin.append(0)\n",
    "        other_bin.append(0)        \n",
    "    else:\n",
    "        senior_bin.append(0)\n",
    "        mid_bin.append(0)\n",
    "        entry_bin.append(0)\n",
    "        other_bin.append(1)        \n",
    "master_df['senior_bin'] = pd.Series(senior_bin)\n",
    "master_df['mid_bin'] = pd.Series(mid_bin)\n",
    "master_df['entry_bin'] = pd.Series(entry_bin)\n",
    "master_df['other_bin'] = pd.Series(other_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sal_avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-838e197be1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#calculates the mean salary or we can use median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_sal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sal_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sal_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmean_sal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4027)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3891)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12408)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sal_avg'"
     ]
    }
   ],
   "source": [
    "#calculates the mean salary or we can use median\n",
    "mean_sal = master_df[master_df['sal_avg'] > 0]['sal_avg'].mean()\n",
    "mean_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#expand on features, this creates the X and y\n",
    "master_df['sal_bin'] = 0\n",
    "master_df.loc[master_df['sal_avg'] > mean_sal,'sal_bin'] = 1\n",
    "features = master_df[(master_df['sal_avg'] > 0) & (master_df['search_city'].notnull())]\n",
    "\n",
    "X = features.loc[:,['search_city','senior_bin','mid_bin','entry_bin','COL_new']]\n",
    "X = pd.get_dummies(X,columns = ['search_city'])\n",
    "y = features.loc[:,'sal_bin']\n",
    "X = X.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.33, random_state = 77) ## create train-test out of the data given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# this is the code from the lab, using gridsearchCV\n",
    "#need to expand on C_vals\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [.1,.5,1]\n",
    "#C_vals = np.linspace(.33,.66,50)\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=3)\n",
    "gs.fit(X_train, Y_train)\n",
    "\n",
    "print gs.best_params_\n",
    "logreg = LogisticRegression(C=gs.best_params_['C'], penalty=gs.best_params_['penalty'])\n",
    "#logreg = LogisticRegression(C=.55, penalty=gs.best_params_['penalty'])\n",
    "cv_model = logreg.fit(X_train, Y_train)\n",
    "cv_pred = cv_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_model.coef_\n",
    "x_list = X.columns.tolist()\n",
    "\n",
    "#need to get coeficients into a list to bring in as a dataframe to pair up with columns\n",
    "\n",
    "\n",
    "#coef_list = cv_model.coef_.tolist("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_over_mean  predicted_under_mean\n",
      "over_mean                    87                    59\n",
      "under_mean                   30                   193\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.87      0.81       223\n",
      "          1       0.74      0.60      0.66       146\n",
      "\n",
      "avg / total       0.76      0.76      0.75       369\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82634068431721852"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = cv_model.decision_function(X_train)\n",
    "conmat = np.array(confusion_matrix(Y_train, cv_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat,index=['over_mean', 'under_mean'],\n",
    "                         columns=['predicted_over_mean','predicted_under_mean'])\n",
    "print confusion\n",
    "# Used to verify the confusion matrix\n",
    "# #confusion\n",
    "# pred_series = pd.Series(cv_pred).to_frame()\n",
    "# y_check = Y_train.to_frame()\n",
    "# y_check.reset_index(inplace = True,drop= True)\n",
    "\n",
    "# conmat_check = pd.concat([y_check,pred_series],axis = 1)\n",
    "# conmat_check[conmat_check['sal_bin']==1][0].sum()\n",
    "# # sub_yscore = y_score_sub.reshape((len(y_score_sub),1))\n",
    "# # sub_yscore.shape\n",
    "\n",
    "print classification_report(Y_train,cv_pred)\n",
    "roc_auc_score(Y_train, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glassdoor_df = pd.read_csv('glassdoor_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>meanPay</th>\n",
       "      <th>City</th>\n",
       "      <th>low_sal</th>\n",
       "      <th>high_sal</th>\n",
       "      <th>sal_avg</th>\n",
       "      <th>entry_bin</th>\n",
       "      <th>mid_bin</th>\n",
       "      <th>senior_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>careerbuilder</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>86172</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>86172</td>\n",
       "      <td>86172</td>\n",
       "      <td>86172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ncr</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>86000 - 94000</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>86000</td>\n",
       "      <td>94000</td>\n",
       "      <td>90000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the home depot</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000 - 104000</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>90000</td>\n",
       "      <td>104000</td>\n",
       "      <td>97000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         company           title         meanPay     City  \\\n",
       "0           0   careerbuilder  Data Scientist           86172  atlanta   \n",
       "1           1             ncr  Data Scientist   86000 - 94000  atlanta   \n",
       "2           2  the home depot  Data Scientist  90000 - 104000  atlanta   \n",
       "\n",
       "   low_sal  high_sal  sal_avg  entry_bin  mid_bin  senior_bin  \n",
       "0    86172     86172    86172          0        1           0  \n",
       "1    86000     94000    90000          0        1           0  \n",
       "2    90000    104000    97000          0        1           0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdoor_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "      <th>jkid</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>post_date</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>search_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta, GA 30338</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Machine learning, data visualization, statisti...</td>\n",
       "      <td>53b7f855d4891e19</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Atlanta, GA 30339</td>\n",
       "      <td>ASSURANT</td>\n",
       "      <td>3+ years of relevant experience in analytics, ...</td>\n",
       "      <td>9ecd8095dd0355f8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>11 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Atlanta, GA 30306 (Virginia-Highland area)</td>\n",
       "      <td>360i</td>\n",
       "      <td>The Associate Data Scientist will be mentored ...</td>\n",
       "      <td>c2b6dcbcb0895072</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Ga. Dept. of Admin. Services</td>\n",
       "      <td>SQL Server knowledge for developing queries an...</td>\n",
       "      <td>70f23d3b618d4b8e</td>\n",
       "      <td>Statistical Data Analyst</td>\n",
       "      <td>$36,000 - $46,000 a year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Data modeling, mining, pattern analysis, data ...</td>\n",
       "      <td>9b253c3eeae5f37a</td>\n",
       "      <td>Analytics Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>11 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlanta, GA 30339</td>\n",
       "      <td>ASSURANT</td>\n",
       "      <td>The primary objective of this position is to e...</td>\n",
       "      <td>ed7467a761020f51</td>\n",
       "      <td>Sr Data Scientist - Fraud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Atlanta, GA 30303 (Five Points area)</td>\n",
       "      <td>Vesta Corporation</td>\n",
       "      <td>Or PhD in Computer Science, Statistics, Applie...</td>\n",
       "      <td>24cec20de39398ca</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Whether we are protecting the American people ...</td>\n",
       "      <td>40d8215afa28f4bb</td>\n",
       "      <td>HEALTH SCIENTIST</td>\n",
       "      <td>$88,305 - $114,802 a year</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Travelport</td>\n",
       "      <td>Developing and implementing advanced analytics...</td>\n",
       "      <td>324aa9db249c02a7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Atlanta, GA 30308 (Old Fourth Ward area)</td>\n",
       "      <td>Stackfolio</td>\n",
       "      <td>A competitive full-time salary as well as a gr...</td>\n",
       "      <td>be3a7444db34e9a3</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>$80,000 a year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>CEB</td>\n",
       "      <td>Serve as an internal subject matter expert, pr...</td>\n",
       "      <td>c13848ddc3456fc4</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7 hours</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Atlanta, GA 30306 (Virginia-Highland area)</td>\n",
       "      <td>360i</td>\n",
       "      <td>Data Scientist will work directly with 360i cl...</td>\n",
       "      <td>abb5e77d57d05bfb</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Kabbage</td>\n",
       "      <td>As a part of the Data Science team, you will d...</td>\n",
       "      <td>6e3ccea1c8472429</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Whether we are protecting the American people ...</td>\n",
       "      <td>ece367560a42bf9b</td>\n",
       "      <td>Health Scientist (Informatics)</td>\n",
       "      <td>$104,349 - $135,656 a year</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Strive Consulting LLC</td>\n",
       "      <td>Preforming SQL queries on large data tables. S...</td>\n",
       "      <td>dedd076d3befa2ae</td>\n",
       "      <td>Mid/Sr Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Cox Automotive</td>\n",
       "      <td>Interprets problems and develops solutions to ...</td>\n",
       "      <td>4dd0428a36b610d7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>LexisNexis</td>\n",
       "      <td>3-5+ years demonstrated applied modeling and a...</td>\n",
       "      <td>739ca94e7a0bed05</td>\n",
       "      <td>Statistical Modeler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>354.0</td>\n",
       "      <td>6 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>State Farm Mutual Automobile Insurance Company</td>\n",
       "      <td>Academic background in quantitative discipline...</td>\n",
       "      <td>d802e1098386cf76</td>\n",
       "      <td>Research Statistician</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>4 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Atlanta, GA 30309 (Midtown area)</td>\n",
       "      <td>HD Supply</td>\n",
       "      <td>Responsible for modeling complex enterprise pr...</td>\n",
       "      <td>5e4122b4e399341b</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>489.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>LexisNexis</td>\n",
       "      <td>Applied modeling and analytics experience in a...</td>\n",
       "      <td>a55cca05efac758d</td>\n",
       "      <td>Principal Statistical Modeler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>354.0</td>\n",
       "      <td>4 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Atlanta, GA 30318 (Rockdale area)</td>\n",
       "      <td>Georgia Tech Research Institute</td>\n",
       "      <td>The Georgia Tech Research Institute's Machine ...</td>\n",
       "      <td>0b18bd331be1a5ca</td>\n",
       "      <td>Machine Learning-Data Science Computer Vision ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.800003</td>\n",
       "      <td>255.0</td>\n",
       "      <td>12 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>krg technology inc</td>\n",
       "      <td>Data scientist with either a Masters or PhD. S...</td>\n",
       "      <td>c033d176ea5a13bf</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Whether we are protecting the American people ...</td>\n",
       "      <td>f7997468ea82b26a</td>\n",
       "      <td>Mathematical Statistician</td>\n",
       "      <td>$104,349 - $135,656 a year</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>SunTrust</td>\n",
       "      <td>Performs sophisticated data analytics (encompa...</td>\n",
       "      <td>16b342fb19d2cf92</td>\n",
       "      <td>Consumer Banking Data Scientist - Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Atlanta, GA 30326 (Buckhead area)</td>\n",
       "      <td>eHire, LLC</td>\n",
       "      <td>Strong background in applying statistical mach...</td>\n",
       "      <td>f0341f282e4dc253</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>$150,000 a year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>Master’s degree in Computer Science, Mathemati...</td>\n",
       "      <td>3ab193931df8ad50</td>\n",
       "      <td>Sr Data Scientist - Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>25 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Atlanta, GA 30303 (Five Points area)</td>\n",
       "      <td>SimplePart</td>\n",
       "      <td>You will be responsible for a team of analysts...</td>\n",
       "      <td>78a5029ce1dc2c53</td>\n",
       "      <td>Director of Business Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 hours</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Atlanta, GA 30338</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist, to...</td>\n",
       "      <td>564598809d60ebbc</td>\n",
       "      <td>Data Scientist, Natural Language Processing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Alpharetta, GA 30022</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>Apply machine learning and statistical techniq...</td>\n",
       "      <td>2eeab08cd59a3296</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>11118.0</td>\n",
       "      <td>20 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NIIT Technologies</td>\n",
       "      <td>Expertise in operations research, applied stat...</td>\n",
       "      <td>42835cf45915a966</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>Data Analytics or Machine Learning nanodegree;...</td>\n",
       "      <td>fefa5d19c1036ec6</td>\n",
       "      <td>Professional Data Scientist BIG DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>14298.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>Atlanta, GA 30309 (Midtown area)</td>\n",
       "      <td>Equifax</td>\n",
       "      <td>Manipulate large data sets, integrate diverse ...</td>\n",
       "      <td>8afe8243cd9b6c14</td>\n",
       "      <td>Statistical Consultant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>220.0</td>\n",
       "      <td>10 hours</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>Atlanta, GA 30338</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Machine learning, data visualization, statisti...</td>\n",
       "      <td>09d2595f347a2619</td>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>25 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>StrategyWise</td>\n",
       "      <td>Technical expertise regarding data models, dat...</td>\n",
       "      <td>5799213023e69929</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>North Highland</td>\n",
       "      <td>Extensive experience with wide array of analyt...</td>\n",
       "      <td>9f50fa0514c0b1aa</td>\n",
       "      <td>Business Intelligence Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.400000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>UCB</td>\n",
       "      <td>Help design, then lead or manage advanced anal...</td>\n",
       "      <td>00b6a44d7f426b8e</td>\n",
       "      <td>Head of Commercial Data and Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>Atlanta, GA 30328</td>\n",
       "      <td>Intercontinental Exchange, Inc.</td>\n",
       "      <td>Investigate and manage large data sets. 2 year...</td>\n",
       "      <td>3de191f59f554a55</td>\n",
       "      <td>Quantitative Analyst (5051)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>And operates under minimal supervision and men...</td>\n",
       "      <td>55dfcaba163b8c89</td>\n",
       "      <td>Senior Data Analyst, Supply Chain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>20610.0</td>\n",
       "      <td>26 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>You will be responsible for working closely wi...</td>\n",
       "      <td>27b511fcc7265dd7</td>\n",
       "      <td>Analytics DevOps Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>10 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Experience with R and large data sets. It will...</td>\n",
       "      <td>7cb01e6c9ce9dfd5</td>\n",
       "      <td>Statistical Analysis Fellowship - CDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>PreVisor</td>\n",
       "      <td>Serve as an internal subject matter expert eit...</td>\n",
       "      <td>b07cde8b257051da</td>\n",
       "      <td>Associate Research Scientist - 6-month intern ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>Duluth, GA 30096</td>\n",
       "      <td>CHASE Professionals</td>\n",
       "      <td>1-3 years of Data Science/Data Analytics. Our ...</td>\n",
       "      <td>869e076b2b2ca58e</td>\n",
       "      <td>Data Scientist/ Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Currently the Branch is leading the developmen...</td>\n",
       "      <td>4928d3911710e6b0</td>\n",
       "      <td>Biostatistics; Statistician Fellowship -- CDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>HDR</td>\n",
       "      <td>We create an unshakable foundation for progres...</td>\n",
       "      <td>0881307458ef3b0c</td>\n",
       "      <td>Project Management Systems Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>10 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>The clinical informatics group fosters collabo...</td>\n",
       "      <td>514f87b53e191e5e</td>\n",
       "      <td>Assistant Professor -TT - Signal Processing &amp; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>And with our Big Data know-how, you’ll discove...</td>\n",
       "      <td>9602654420268460</td>\n",
       "      <td>Big Data Technical Intern I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>14298.0</td>\n",
       "      <td>26 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>PreVisor</td>\n",
       "      <td>Serve as an internal subject matter expert, pr...</td>\n",
       "      <td>9b75487e5b14d1d4</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Bluefusioninc</td>\n",
       "      <td>Experience in formulating and implementing opt...</td>\n",
       "      <td>bd6b2f66d91ef38a</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Visionaire Partners</td>\n",
       "      <td>Once defined, you will be responsible in trans...</td>\n",
       "      <td>b4a8e28f88d0b080</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.199997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Supervised and Un-supervised machine learning ...</td>\n",
       "      <td>fd3512169c7325e1</td>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Senior Data Scientist and Analytics Lead with ...</td>\n",
       "      <td>d67b0f93e14af031</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$100,000 - $125,000 a year</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Northrop Grumman</td>\n",
       "      <td>Review project data and assess quality. Organi...</td>\n",
       "      <td>a2d937a8d7efb91e</td>\n",
       "      <td>Health Research Analyst 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>14 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Norcross, GA</td>\n",
       "      <td>CI Radar</td>\n",
       "      <td>Become a subject matter expert on clients’ mar...</td>\n",
       "      <td>adf27202c0ea4526</td>\n",
       "      <td>Business Research Analyst - Entry Level</td>\n",
       "      <td>$30,000 - $32,000 a year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>RaceTrac</td>\n",
       "      <td>Communicates project plans and articulates rol...</td>\n",
       "      <td>cefa2b3bf3741997</td>\n",
       "      <td>Optimization Research Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>694.0</td>\n",
       "      <td>20 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>Atlanta, GA 30324 (Buckhead area)</td>\n",
       "      <td>Wabash Solutions</td>\n",
       "      <td>Strong knowledge of operations research and da...</td>\n",
       "      <td>b4323c1b2bb13cb9</td>\n",
       "      <td>Operations Research Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Aptonet, inc</td>\n",
       "      <td>As a data engineer you’ll use your sense of ur...</td>\n",
       "      <td>09dcf95bfed022f5</td>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30+ days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Atlanta, GA 30326 (Buckhead area)</td>\n",
       "      <td>JLL</td>\n",
       "      <td>Proactively deliver information and insights o...</td>\n",
       "      <td>06fb0a51e02a9053</td>\n",
       "      <td>Sr Research Analyst (Industrial)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>ADP</td>\n",
       "      <td>At ADP, the world's largest B2B cloud company,...</td>\n",
       "      <td>8c8f1cb4e68c81bb</td>\n",
       "      <td>Director of Application Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Atlanta, GA 30318 (Rockdale area)</td>\n",
       "      <td>Georgia Tech Research Institute</td>\n",
       "      <td>Our expert scientists and engineers turn ideas...</td>\n",
       "      <td>463e45aca1e4a7fd</td>\n",
       "      <td>Applications Engineer and Intelligence Analyst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.800003</td>\n",
       "      <td>255.0</td>\n",
       "      <td>25 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Atlanta, GA 30318 (Rockdale area)</td>\n",
       "      <td>Georgia Tech Research Institute</td>\n",
       "      <td>GTRI is a group of world-class engineers and s...</td>\n",
       "      <td>f3c71b357a04c584</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.800003</td>\n",
       "      <td>255.0</td>\n",
       "      <td>19 days</td>\n",
       "      <td>2016-10-17 23:45:52.664015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                    location  \\\n",
       "0            0                           Atlanta, GA 30338   \n",
       "1            1                           Atlanta, GA 30339   \n",
       "2            2  Atlanta, GA 30306 (Virginia-Highland area)   \n",
       "3            3                                 Atlanta, GA   \n",
       "4            4                                 Atlanta, GA   \n",
       "5            5                           Atlanta, GA 30339   \n",
       "6            6        Atlanta, GA 30303 (Five Points area)   \n",
       "7            7                                 Atlanta, GA   \n",
       "8            8                                 Atlanta, GA   \n",
       "9            9    Atlanta, GA 30308 (Old Fourth Ward area)   \n",
       "10          10                                 Atlanta, GA   \n",
       "11          11  Atlanta, GA 30306 (Virginia-Highland area)   \n",
       "12          12                                 Atlanta, GA   \n",
       "13          13                                 Atlanta, GA   \n",
       "14          14                                 Atlanta, GA   \n",
       "15          15                                 Atlanta, GA   \n",
       "16          16                        Alpharetta, GA 30005   \n",
       "17          17                                 Atlanta, GA   \n",
       "18          18            Atlanta, GA 30309 (Midtown area)   \n",
       "19          19                        Alpharetta, GA 30005   \n",
       "20          20           Atlanta, GA 30318 (Rockdale area)   \n",
       "21          21                              Alpharetta, GA   \n",
       "22          22                                 Atlanta, GA   \n",
       "23          23                                 Atlanta, GA   \n",
       "24          24           Atlanta, GA 30326 (Buckhead area)   \n",
       "25          25                                 Atlanta, GA   \n",
       "26          26        Atlanta, GA 30303 (Five Points area)   \n",
       "27          27                           Atlanta, GA 30338   \n",
       "28          28                        Alpharetta, GA 30022   \n",
       "29          29                                 Atlanta, GA   \n",
       "..         ...                                         ...   \n",
       "70          70                              Alpharetta, GA   \n",
       "71          71            Atlanta, GA 30309 (Midtown area)   \n",
       "72          72                           Atlanta, GA 30338   \n",
       "73          73                                 Atlanta, GA   \n",
       "74          74                                 Atlanta, GA   \n",
       "75          75                                 Atlanta, GA   \n",
       "76          76                           Atlanta, GA 30328   \n",
       "77          77                                 Atlanta, GA   \n",
       "78          78                                 Atlanta, GA   \n",
       "79          79                                 Atlanta, GA   \n",
       "80          80                                 Atlanta, GA   \n",
       "81          81                            Duluth, GA 30096   \n",
       "82          82                                 Atlanta, GA   \n",
       "83          83                                 Atlanta, GA   \n",
       "84          84                                 Atlanta, GA   \n",
       "85          85                              Alpharetta, GA   \n",
       "86          86                                 Atlanta, GA   \n",
       "87          87                                 Atlanta, GA   \n",
       "88          88                                 Atlanta, GA   \n",
       "89          89                                 Atlanta, GA   \n",
       "90          90                                 Atlanta, GA   \n",
       "91          91                                 Atlanta, GA   \n",
       "92          92                                Norcross, GA   \n",
       "93          93                                 Atlanta, GA   \n",
       "94          94           Atlanta, GA 30324 (Buckhead area)   \n",
       "95          95                                 Atlanta, GA   \n",
       "96          96           Atlanta, GA 30326 (Buckhead area)   \n",
       "97          97                        Alpharetta, GA 30005   \n",
       "98          98           Atlanta, GA 30318 (Rockdale area)   \n",
       "99          99           Atlanta, GA 30318 (Rockdale area)   \n",
       "\n",
       "                                           company  \\\n",
       "0                                             KPMG   \n",
       "1                                         ASSURANT   \n",
       "2                                             360i   \n",
       "3                     Ga. Dept. of Admin. Services   \n",
       "4                                        Honeywell   \n",
       "5                                         ASSURANT   \n",
       "6                                Vesta Corporation   \n",
       "7       Centers for Disease Control and Prevention   \n",
       "8                                       Travelport   \n",
       "9                                       Stackfolio   \n",
       "10                                             CEB   \n",
       "11                                            360i   \n",
       "12                                         Kabbage   \n",
       "13      Centers for Disease Control and Prevention   \n",
       "14                           Strive Consulting LLC   \n",
       "15                                  Cox Automotive   \n",
       "16                                      LexisNexis   \n",
       "17  State Farm Mutual Automobile Insurance Company   \n",
       "18                                       HD Supply   \n",
       "19                                      LexisNexis   \n",
       "20                 Georgia Tech Research Institute   \n",
       "21                              krg technology inc   \n",
       "22      Centers for Disease Control and Prevention   \n",
       "23                                        SunTrust   \n",
       "24                                      eHire, LLC   \n",
       "25                                       Honeywell   \n",
       "26                                      SimplePart   \n",
       "27                                            KPMG   \n",
       "28                                         Verizon   \n",
       "29                               NIIT Technologies   \n",
       "..                                             ...   \n",
       "70                                            AT&T   \n",
       "71                                         Equifax   \n",
       "72                                            KPMG   \n",
       "73                                    StrategyWise   \n",
       "74                                  North Highland   \n",
       "75                                             UCB   \n",
       "76                 Intercontinental Exchange, Inc.   \n",
       "77                                      Home Depot   \n",
       "78                                       Honeywell   \n",
       "79               Oak Ridge Associated Universities   \n",
       "80                                        PreVisor   \n",
       "81                             CHASE Professionals   \n",
       "82               Oak Ridge Associated Universities   \n",
       "83                                             HDR   \n",
       "84                                Emory University   \n",
       "85                                            AT&T   \n",
       "86                                        PreVisor   \n",
       "87                                   Bluefusioninc   \n",
       "88                             Visionaire Partners   \n",
       "89                                       Capgemini   \n",
       "90                             Analytic Recruiting   \n",
       "91                                Northrop Grumman   \n",
       "92                                        CI Radar   \n",
       "93                                        RaceTrac   \n",
       "94                                Wabash Solutions   \n",
       "95                                    Aptonet, inc   \n",
       "96                                             JLL   \n",
       "97                                             ADP   \n",
       "98                 Georgia Tech Research Institute   \n",
       "99                 Georgia Tech Research Institute   \n",
       "\n",
       "                                              summary              jkid  \\\n",
       "0   Machine learning, data visualization, statisti...  53b7f855d4891e19   \n",
       "1   3+ years of relevant experience in analytics, ...  9ecd8095dd0355f8   \n",
       "2   The Associate Data Scientist will be mentored ...  c2b6dcbcb0895072   \n",
       "3   SQL Server knowledge for developing queries an...  70f23d3b618d4b8e   \n",
       "4   Data modeling, mining, pattern analysis, data ...  9b253c3eeae5f37a   \n",
       "5   The primary objective of this position is to e...  ed7467a761020f51   \n",
       "6   Or PhD in Computer Science, Statistics, Applie...  24cec20de39398ca   \n",
       "7   Whether we are protecting the American people ...  40d8215afa28f4bb   \n",
       "8   Developing and implementing advanced analytics...  324aa9db249c02a7   \n",
       "9   A competitive full-time salary as well as a gr...  be3a7444db34e9a3   \n",
       "10  Serve as an internal subject matter expert, pr...  c13848ddc3456fc4   \n",
       "11  Data Scientist will work directly with 360i cl...  abb5e77d57d05bfb   \n",
       "12  As a part of the Data Science team, you will d...  6e3ccea1c8472429   \n",
       "13  Whether we are protecting the American people ...  ece367560a42bf9b   \n",
       "14  Preforming SQL queries on large data tables. S...  dedd076d3befa2ae   \n",
       "15  Interprets problems and develops solutions to ...  4dd0428a36b610d7   \n",
       "16  3-5+ years demonstrated applied modeling and a...  739ca94e7a0bed05   \n",
       "17  Academic background in quantitative discipline...  d802e1098386cf76   \n",
       "18  Responsible for modeling complex enterprise pr...  5e4122b4e399341b   \n",
       "19  Applied modeling and analytics experience in a...  a55cca05efac758d   \n",
       "20  The Georgia Tech Research Institute's Machine ...  0b18bd331be1a5ca   \n",
       "21  Data scientist with either a Masters or PhD. S...  c033d176ea5a13bf   \n",
       "22  Whether we are protecting the American people ...  f7997468ea82b26a   \n",
       "23  Performs sophisticated data analytics (encompa...  16b342fb19d2cf92   \n",
       "24  Strong background in applying statistical mach...  f0341f282e4dc253   \n",
       "25  Master’s degree in Computer Science, Mathemati...  3ab193931df8ad50   \n",
       "26  You will be responsible for a team of analysts...  78a5029ce1dc2c53   \n",
       "27  KPMG is currently seeking a Data Scientist, to...  564598809d60ebbc   \n",
       "28  Apply machine learning and statistical techniq...  2eeab08cd59a3296   \n",
       "29  Expertise in operations research, applied stat...  42835cf45915a966   \n",
       "..                                                ...               ...   \n",
       "70  Data Analytics or Machine Learning nanodegree;...  fefa5d19c1036ec6   \n",
       "71  Manipulate large data sets, integrate diverse ...  8afe8243cd9b6c14   \n",
       "72  Machine learning, data visualization, statisti...  09d2595f347a2619   \n",
       "73  Technical expertise regarding data models, dat...  5799213023e69929   \n",
       "74  Extensive experience with wide array of analyt...  9f50fa0514c0b1aa   \n",
       "75  Help design, then lead or manage advanced anal...  00b6a44d7f426b8e   \n",
       "76  Investigate and manage large data sets. 2 year...  3de191f59f554a55   \n",
       "77  And operates under minimal supervision and men...  55dfcaba163b8c89   \n",
       "78  You will be responsible for working closely wi...  27b511fcc7265dd7   \n",
       "79  Experience with R and large data sets. It will...  7cb01e6c9ce9dfd5   \n",
       "80  Serve as an internal subject matter expert eit...  b07cde8b257051da   \n",
       "81  1-3 years of Data Science/Data Analytics. Our ...  869e076b2b2ca58e   \n",
       "82  Currently the Branch is leading the developmen...  4928d3911710e6b0   \n",
       "83  We create an unshakable foundation for progres...  0881307458ef3b0c   \n",
       "84  The clinical informatics group fosters collabo...  514f87b53e191e5e   \n",
       "85  And with our Big Data know-how, you’ll discove...  9602654420268460   \n",
       "86  Serve as an internal subject matter expert, pr...  9b75487e5b14d1d4   \n",
       "87  Experience in formulating and implementing opt...  bd6b2f66d91ef38a   \n",
       "88  Once defined, you will be responsible in trans...  b4a8e28f88d0b080   \n",
       "89  Supervised and Un-supervised machine learning ...  fd3512169c7325e1   \n",
       "90  Senior Data Scientist and Analytics Lead with ...  d67b0f93e14af031   \n",
       "91  Review project data and assess quality. Organi...  a2d937a8d7efb91e   \n",
       "92  Become a subject matter expert on clients’ mar...  adf27202c0ea4526   \n",
       "93  Communicates project plans and articulates rol...  cefa2b3bf3741997   \n",
       "94  Strong knowledge of operations research and da...  b4323c1b2bb13cb9   \n",
       "95  As a data engineer you’ll use your sense of ur...  09dcf95bfed022f5   \n",
       "96  Proactively deliver information and insights o...  06fb0a51e02a9053   \n",
       "97  At ADP, the world's largest B2B cloud company,...  8c8f1cb4e68c81bb   \n",
       "98  Our expert scientists and engineers turn ideas...  463e45aca1e4a7fd   \n",
       "99  GTRI is a group of world-class engineers and s...  f3c71b357a04c584   \n",
       "\n",
       "                                                title  \\\n",
       "0                                      Data Scientist   \n",
       "1                                      Data Scientist   \n",
       "2                            Associate Data Scientist   \n",
       "3                            Statistical Data Analyst   \n",
       "4                            Analytics Data Scientist   \n",
       "5                           Sr Data Scientist - Fraud   \n",
       "6                               Senior Data Scientist   \n",
       "7                                    HEALTH SCIENTIST   \n",
       "8                                      Data Scientist   \n",
       "9                                 Lead Data Scientist   \n",
       "10                                 Research Scientist   \n",
       "11                                  Sr Data Scientist   \n",
       "12                                     Data Scientist   \n",
       "13                     Health Scientist (Informatics)   \n",
       "14                              Mid/Sr Data Scientist   \n",
       "15                                     Data Scientist   \n",
       "16                                Statistical Modeler   \n",
       "17                              Research Statistician   \n",
       "18                                     Data Scientist   \n",
       "19                      Principal Statistical Modeler   \n",
       "20  Machine Learning-Data Science Computer Vision ...   \n",
       "21                                     Data Scientist   \n",
       "22                          Mathematical Statistician   \n",
       "23      Consumer Banking Data Scientist - Atlanta, GA   \n",
       "24                                  Sr Data Scientist   \n",
       "25                    Sr Data Scientist - Atlanta, GA   \n",
       "26                     Director of Business Analytics   \n",
       "27        Data Scientist, Natural Language Processing   \n",
       "28                              Senior Data Scientist   \n",
       "29                                     Data Scientist   \n",
       "..                                                ...   \n",
       "70               Professional Data Scientist BIG DATA   \n",
       "71                             Statistical Consultant   \n",
       "72                           Manager - Data Scientist   \n",
       "73                                       Data Analyst   \n",
       "74               Business Intelligence Data Scientist   \n",
       "75              Head of Commercial Data and Analytics   \n",
       "76                        Quantitative Analyst (5051)   \n",
       "77                  Senior Data Analyst, Supply Chain   \n",
       "78                          Analytics DevOps Engineer   \n",
       "79              Statistical Analysis Fellowship - CDC   \n",
       "80  Associate Research Scientist - 6-month intern ...   \n",
       "81                       Data Scientist/ Data Analyst   \n",
       "82      Biostatistics; Statistician Fellowship -- CDC   \n",
       "83                 Project Management Systems Analyst   \n",
       "84  Assistant Professor -TT - Signal Processing & ...   \n",
       "85                        Big Data Technical Intern I   \n",
       "86                                 Research Scientist   \n",
       "87                        Operations Research Analyst   \n",
       "88                                     Data Scientist   \n",
       "89                            Data Science Consultant   \n",
       "90                              Senior Data Scientist   \n",
       "91                          Health Research Analyst 2   \n",
       "92            Business Research Analyst - Entry Level   \n",
       "93                      Optimization Research Analyst   \n",
       "94                        Operations Research Analyst   \n",
       "95                         Big Data Software Engineer   \n",
       "96                   Sr Research Analyst (Industrial)   \n",
       "97                Director of Application Development   \n",
       "98  Applications Engineer and Intelligence Analyst...   \n",
       "99                                 Research Scientist   \n",
       "\n",
       "                        salary      stars  reviews post_date  \\\n",
       "0                          NaN  51.000000   1768.0    3 days   \n",
       "1                          NaN  43.200000   1108.0   11 days   \n",
       "2                          NaN  51.000000      9.0   12 days   \n",
       "3     $36,000 - $46,000 a year        NaN      NaN    6 days   \n",
       "4                          NaN  44.400000   3477.0   11 days   \n",
       "5                          NaN  43.200000   1108.0    2 days   \n",
       "6                          NaN  40.200000     31.0   10 days   \n",
       "7    $88,305 - $114,802 a year  54.000000     64.0    2 days   \n",
       "8                          NaN  51.600000     52.0  30+ days   \n",
       "9               $80,000 a year        NaN      NaN  30+ days   \n",
       "10                         NaN  40.800000     72.0   7 hours   \n",
       "11                         NaN  51.000000      9.0   20 days   \n",
       "12                         NaN        NaN      NaN  30+ days   \n",
       "13  $104,349 - $135,656 a year  54.000000     64.0    3 days   \n",
       "14                         NaN        NaN      NaN    7 days   \n",
       "15                         NaN  40.800000     42.0   13 days   \n",
       "16                         NaN  43.800000    354.0    6 days   \n",
       "17                         NaN  51.000000   3358.0    4 days   \n",
       "18                         NaN  42.000000    489.0  30+ days   \n",
       "19                         NaN  43.800000    354.0    4 days   \n",
       "20                         NaN  52.800003    255.0   12 days   \n",
       "21                         NaN        NaN      NaN  30+ days   \n",
       "22  $104,349 - $135,656 a year  54.000000     64.0   17 days   \n",
       "23                         NaN  42.600000   2101.0  30+ days   \n",
       "24             $150,000 a year        NaN      NaN   17 days   \n",
       "25                         NaN  44.400000   3477.0   25 days   \n",
       "26                         NaN        NaN      NaN   5 hours   \n",
       "27                         NaN  51.000000   1768.0    3 days   \n",
       "28                         NaN  44.400000  11118.0   20 days   \n",
       "29                         NaN  42.600000    122.0  30+ days   \n",
       "..                         ...        ...      ...       ...   \n",
       "70                         NaN  44.400000  14298.0  30+ days   \n",
       "71                         NaN  43.200000    220.0  10 hours   \n",
       "72                         NaN  51.000000   1768.0   25 days   \n",
       "73                         NaN        NaN      NaN  30+ days   \n",
       "74                         NaN  41.400000     18.0  30+ days   \n",
       "75                         NaN  42.600000     54.0   15 days   \n",
       "76                         NaN        NaN      NaN  30+ days   \n",
       "77                         NaN  43.800000  20610.0   26 days   \n",
       "78                         NaN  44.400000   3477.0   10 days   \n",
       "79                         NaN  43.200000     15.0  30+ days   \n",
       "80                         NaN        NaN      NaN   28 days   \n",
       "81                         NaN  43.800000    166.0    3 days   \n",
       "82                         NaN  43.200000     15.0  30+ days   \n",
       "83                         NaN  51.000000    122.0   10 days   \n",
       "84                         NaN  51.600000    254.0   17 days   \n",
       "85                         NaN  44.400000  14298.0   26 days   \n",
       "86                         NaN        NaN      NaN  30+ days   \n",
       "87                         NaN        NaN      NaN   19 days   \n",
       "88                         NaN  52.199997      5.0   12 days   \n",
       "89                         NaN  43.800000   2002.0  30+ days   \n",
       "90  $100,000 - $125,000 a year  51.000000      2.0  30+ days   \n",
       "91                         NaN  51.000000   2126.0   14 days   \n",
       "92    $30,000 - $32,000 a year        NaN      NaN   12 days   \n",
       "93                         NaN  43.200000    694.0   20 days   \n",
       "94                         NaN        NaN      NaN   17 days   \n",
       "95                         NaN        NaN      NaN  30+ days   \n",
       "96                         NaN  43.800000    759.0    6 days   \n",
       "97                         NaN  44.400000   1657.0    3 days   \n",
       "98                         NaN  52.800003    255.0   25 days   \n",
       "99                         NaN  52.800003    255.0   19 days   \n",
       "\n",
       "                     pull_date search_city  \n",
       "0   2016-10-17 23:45:52.664015     Atlanta  \n",
       "1   2016-10-17 23:45:52.664015     Atlanta  \n",
       "2   2016-10-17 23:45:52.664015     Atlanta  \n",
       "3   2016-10-17 23:45:52.664015     Atlanta  \n",
       "4   2016-10-17 23:45:52.664015     Atlanta  \n",
       "5   2016-10-17 23:45:52.664015     Atlanta  \n",
       "6   2016-10-17 23:45:52.664015     Atlanta  \n",
       "7   2016-10-17 23:45:52.664015     Atlanta  \n",
       "8   2016-10-17 23:45:52.664015     Atlanta  \n",
       "9   2016-10-17 23:45:52.664015     Atlanta  \n",
       "10  2016-10-17 23:45:52.664015     Atlanta  \n",
       "11  2016-10-17 23:45:52.664015     Atlanta  \n",
       "12  2016-10-17 23:45:52.664015     Atlanta  \n",
       "13  2016-10-17 23:45:52.664015     Atlanta  \n",
       "14  2016-10-17 23:45:52.664015     Atlanta  \n",
       "15  2016-10-17 23:45:52.664015     Atlanta  \n",
       "16  2016-10-17 23:45:52.664015     Atlanta  \n",
       "17  2016-10-17 23:45:52.664015     Atlanta  \n",
       "18  2016-10-17 23:45:52.664015     Atlanta  \n",
       "19  2016-10-17 23:45:52.664015     Atlanta  \n",
       "20  2016-10-17 23:45:52.664015     Atlanta  \n",
       "21  2016-10-17 23:45:52.664015     Atlanta  \n",
       "22  2016-10-17 23:45:52.664015     Atlanta  \n",
       "23  2016-10-17 23:45:52.664015     Atlanta  \n",
       "24  2016-10-17 23:45:52.664015     Atlanta  \n",
       "25  2016-10-17 23:45:52.664015     Atlanta  \n",
       "26  2016-10-17 23:45:52.664015     Atlanta  \n",
       "27  2016-10-17 23:45:52.664015     Atlanta  \n",
       "28  2016-10-17 23:45:52.664015     Atlanta  \n",
       "29  2016-10-17 23:45:52.664015     Atlanta  \n",
       "..                         ...         ...  \n",
       "70  2016-10-17 23:45:52.664015     Atlanta  \n",
       "71  2016-10-17 23:45:52.664015     Atlanta  \n",
       "72  2016-10-17 23:45:52.664015     Atlanta  \n",
       "73  2016-10-17 23:45:52.664015     Atlanta  \n",
       "74  2016-10-17 23:45:52.664015     Atlanta  \n",
       "75  2016-10-17 23:45:52.664015     Atlanta  \n",
       "76  2016-10-17 23:45:52.664015     Atlanta  \n",
       "77  2016-10-17 23:45:52.664015     Atlanta  \n",
       "78  2016-10-17 23:45:52.664015     Atlanta  \n",
       "79  2016-10-17 23:45:52.664015     Atlanta  \n",
       "80  2016-10-17 23:45:52.664015     Atlanta  \n",
       "81  2016-10-17 23:45:52.664015     Atlanta  \n",
       "82  2016-10-17 23:45:52.664015     Atlanta  \n",
       "83  2016-10-17 23:45:52.664015     Atlanta  \n",
       "84  2016-10-17 23:45:52.664015     Atlanta  \n",
       "85  2016-10-17 23:45:52.664015     Atlanta  \n",
       "86  2016-10-17 23:45:52.664015     Atlanta  \n",
       "87  2016-10-17 23:45:52.664015     Atlanta  \n",
       "88  2016-10-17 23:45:52.664015     Atlanta  \n",
       "89  2016-10-17 23:45:52.664015     Atlanta  \n",
       "90  2016-10-17 23:45:52.664015     Atlanta  \n",
       "91  2016-10-17 23:45:52.664015     Atlanta  \n",
       "92  2016-10-17 23:45:52.664015     Atlanta  \n",
       "93  2016-10-17 23:45:52.664015     Atlanta  \n",
       "94  2016-10-17 23:45:52.664015     Atlanta  \n",
       "95  2016-10-17 23:45:52.664015     Atlanta  \n",
       "96  2016-10-17 23:45:52.664015     Atlanta  \n",
       "97  2016-10-17 23:45:52.664015     Atlanta  \n",
       "98  2016-10-17 23:45:52.664015     Atlanta  \n",
       "99  2016-10-17 23:45:52.664015     Atlanta  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "1. Some of the salaries are not yearly but hourly, these will be useful to us for now\n",
    "2. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Filter out the salaries that are not yearly (filter those that refer to hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
